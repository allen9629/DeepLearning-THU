{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvHVtDiHhpy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn,functional\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe, CharNGram, FastText\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSy-vzxiO7G",
        "colab_type": "text"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsdzdC5HiSZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "65571571-3035-41f1-e715-13272435958e"
      },
      "source": [
        "TEXT = data.Field()\n",
        "LABEL = data.Field(sequential=False,dtype=torch.long)\n",
        "train, val, test = datasets.SST.splits(\n",
        "    TEXT, LABEL, fine_grained=True, train_subtrees=False)\n",
        "\n",
        "# print information about the data\n",
        "print('train.fields', train.fields)\n",
        "print('len(train)', len(train))\n",
        "print('vars(train[0])', vars(train[0]))\n",
        "\n",
        "# build the vocabulary\n",
        "# you can use other pretrained vectors, refer to https://github.com/pytorch/text/blob/master/torchtext/vocab.py\n",
        "TEXT.build_vocab(train, vectors=Vectors(name='vector.txt', cache='drive/My Drive/Colab Notebooks/data'))\n",
        "LABEL.build_vocab(train)\n",
        "# We can also see the vocabulary directly using either the stoi (string to int) or itos (int to string) method.\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "\n",
        "# print vocab information\n",
        "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
        "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\n",
        "\n",
        "# make iterator for splits\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train, val, test), batch_size=64)\n",
        "\n",
        "# print batch information\n",
        "batch = next(iter(train_iter)) # for batch in train_iter\n",
        "print(batch.text) # input sequence\n",
        "print(batch.label) # groud truth"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.fields {'text': <torchtext.data.field.Field object at 0x7fa89a0f8978>, 'label': <torchtext.data.field.Field object at 0x7fa89a0f8940>}\n",
            "len(train) 8544\n",
            "vars(train[0]) {'text': ['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century', \"'s\", 'new', '``', 'Conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean-Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.'], 'label': 'positive'}\n",
            "['<unk>', '<pad>', '.', ',', 'the', 'and', 'a', 'of', 'to', \"'s\"]\n",
            "defaultdict(<function _default_unk_index at 0x7fa89a199400>, {'<unk>': 0, 'positive': 1, 'negative': 2, 'neutral': 3, 'very positive': 4, 'very negative': 5})\n",
            "[('.', 8024), (',', 7131), ('the', 6037), ('and', 4431), ('a', 4403), ('of', 4386), ('to', 2995), (\"'s\", 2544), ('is', 2536), ('that', 1915), ('in', 1789), ('it', 1775), ('The', 1265), ('as', 1200), ('film', 1152), ('but', 1076), ('with', 1071), ('for', 963), ('movie', 959), ('its', 912)]\n",
            "len(TEXT.vocab) 18280\n",
            "TEXT.vocab.vectors.size() torch.Size([18280, 300])\n",
            "tensor([[   14,    14,    22,  ...,  8942, 10557,   166],\n",
            "        [  370,   318,  1076,  ...,  7750,   446,    23],\n",
            "        [    7,    34,     5,  ...,  2057,     3,  8883],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1]])\n",
            "tensor([1, 2, 2, 2, 1, 5, 5, 5, 2, 1, 3, 1, 4, 2, 4, 4, 2, 2, 5, 2, 4, 1, 2, 3,\n",
            "        1, 2, 1, 2, 4, 4, 2, 4, 5, 2, 1, 4, 5, 1, 3, 4, 3, 5, 2, 1, 3, 3, 1, 4,\n",
            "        1, 2, 4, 5, 4, 1, 1, 3, 2, 2, 2, 4, 4, 2, 3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aks_xWjemTVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "602f5d8f-e12a-4e44-e7e0-d49f2f5a0cb3"
      },
      "source": [
        "# Copy the pre-trained word embeddings we loaded earlier into the embedding layer of our model.\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18280, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aPxwslCllMB",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBLTpr6JlpVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SN(nn.Module):\n",
        "    def __init__(self,embed_size, num_hiddens, num_layers,\n",
        "                 bidirectional, labels, **kwargs):\n",
        "        super(SN, self).__init__(**kwargs)\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=self.num_hiddens,\n",
        "                               num_layers=num_layers, bidirectional=self.bidirectional,\n",
        "                               dropout=0.4)\n",
        "        if self.bidirectional:\n",
        "            self.fc = nn.Linear(num_hiddens * 4, labels)\n",
        "        else:\n",
        "            self.fc = nn.Linear(num_hiddens, labels)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.dropout(self.embedding(inputs))\n",
        "        states, hidden = self.encoder(embeddings)\n",
        "        encoding = torch.cat([states[0], states[-1]], dim=1)\n",
        "        \n",
        "        out = self.dropout(self.fc(encoding))\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXnSecj8vDWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9db2a84c-9582-4291-fb23-4fe6351f9abb"
      },
      "source": [
        "embed_size = 300\n",
        "num_hiddens = 100\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "labels = 5\n",
        "batch_size = 256\n",
        "\n",
        "model = SN(embed_size=embed_size,num_hiddens=num_hiddens, num_layers=num_layers,bidirectional=bidirectional,labels=labels)\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SN(\n",
            "  (embedding): Embedding(18280, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, dropout=0.4, bidirectional=True)\n",
            "  (fc): Linear(in_features=400, out_features=5, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR3GhnIZxS8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum =0.9, weight_decay=1e-5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKkFB1_CE3ok",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqmyAIWxjp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0f226455-9ba2-48bd-88e6-b5a1340bf559"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0120,  0.2075, -0.1258,  ...,  0.1387, -0.3605, -0.0350],\n",
              "        ...,\n",
              "        [ 0.0495, -0.2737, -0.2819,  ..., -0.2686,  0.5445,  0.1999],\n",
              "        [ 0.8430, -0.0559, -0.0837,  ...,  0.9208, -0.2708, -0.4322],\n",
              "        [ 0.4218,  0.2891,  0.6224,  ..., -0.0994, -0.3216, -0.2066]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwr99T26yGJJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZVOd29ByJ8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5fcf372-bcb2-4853-d03e-7b6b52c6ca75"
      },
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val, test), batch_size=batch_size,shuffle=True)\n",
        "epochs = 1000\n",
        "training_loss =[]\n",
        "validation_loss =[]\n",
        "validation_acc =[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.zero_grad()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    accuracy = 0\n",
        "    for batch in train_iter:\n",
        "        text = batch.text.to(device)\n",
        "        label = batch.label-1\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(text)\n",
        "        loss = criterion(output,label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        accuracy += torch.sum(torch.argmax(output,1)==label).item()/256\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_acc = 0\n",
        "    for validation_batch in val_iter:\n",
        "        validation_text = validation_batch.text.to(device)\n",
        "        validation_label = validation_batch.label-1\n",
        "        validation_label = validation_label.to(device)\n",
        "        validation_output = model.forward(validation_text)\n",
        "\n",
        "        valid_loss += criterion(validation_output,validation_label).item()\n",
        "        valid_acc += torch.sum(torch.argmax(validation_output,1)==validation_label).cpu().item()/256\n",
        "\n",
        "    training_loss.append(train_loss/len(train_iter))\n",
        "    validation_loss.append(valid_loss/len(val_iter))\n",
        "    validation_acc.append(valid_acc/len(val_iter))\n",
        "\n",
        "    print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
        "              \"Train Loss: {:.3f}.. \".format(train_loss/len(train_iter)),\n",
        "              \"Train_Acc: {:.3f}.. \".format(accuracy/len(train_iter)),\n",
        "              \"Val Loss: {:.3f}.. \".format(valid_loss/len(val_iter)),\n",
        "              \"Val_Acc: {:.3f}\".format(valid_acc/len(val_iter)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/1000..  Train Loss: 1.600..  Train_Acc: 0.243..  Val Loss: 1.591..  Val_Acc: 0.218\n",
            "Epoch: 2/1000..  Train Loss: 1.587..  Train_Acc: 0.260..  Val Loss: 1.585..  Val_Acc: 0.218\n",
            "Epoch: 3/1000..  Train Loss: 1.588..  Train_Acc: 0.258..  Val Loss: 1.584..  Val_Acc: 0.218\n",
            "Epoch: 4/1000..  Train Loss: 1.590..  Train_Acc: 0.247..  Val Loss: 1.584..  Val_Acc: 0.218\n",
            "Epoch: 5/1000..  Train Loss: 1.586..  Train_Acc: 0.259..  Val Loss: 1.582..  Val_Acc: 0.242\n",
            "Epoch: 6/1000..  Train Loss: 1.587..  Train_Acc: 0.251..  Val Loss: 1.581..  Val_Acc: 0.261\n",
            "Epoch: 7/1000..  Train Loss: 1.586..  Train_Acc: 0.259..  Val Loss: 1.581..  Val_Acc: 0.225\n",
            "Epoch: 8/1000..  Train Loss: 1.584..  Train_Acc: 0.257..  Val Loss: 1.579..  Val_Acc: 0.258\n",
            "Epoch: 9/1000..  Train Loss: 1.584..  Train_Acc: 0.265..  Val Loss: 1.579..  Val_Acc: 0.229\n",
            "Epoch: 10/1000..  Train Loss: 1.585..  Train_Acc: 0.261..  Val Loss: 1.576..  Val_Acc: 0.278\n",
            "Epoch: 11/1000..  Train Loss: 1.579..  Train_Acc: 0.277..  Val Loss: 1.573..  Val_Acc: 0.272\n",
            "Epoch: 12/1000..  Train Loss: 1.573..  Train_Acc: 0.276..  Val Loss: 1.565..  Val_Acc: 0.289\n",
            "Epoch: 13/1000..  Train Loss: 1.569..  Train_Acc: 0.281..  Val Loss: 1.546..  Val_Acc: 0.299\n",
            "Epoch: 14/1000..  Train Loss: 1.561..  Train_Acc: 0.293..  Val Loss: 1.533..  Val_Acc: 0.316\n",
            "Epoch: 15/1000..  Train Loss: 1.556..  Train_Acc: 0.295..  Val Loss: 1.536..  Val_Acc: 0.319\n",
            "Epoch: 16/1000..  Train Loss: 1.548..  Train_Acc: 0.298..  Val Loss: 1.520..  Val_Acc: 0.316\n",
            "Epoch: 17/1000..  Train Loss: 1.555..  Train_Acc: 0.293..  Val Loss: 1.543..  Val_Acc: 0.285\n",
            "Epoch: 18/1000..  Train Loss: 1.546..  Train_Acc: 0.311..  Val Loss: 1.520..  Val_Acc: 0.323\n",
            "Epoch: 19/1000..  Train Loss: 1.538..  Train_Acc: 0.319..  Val Loss: 1.513..  Val_Acc: 0.326\n",
            "Epoch: 20/1000..  Train Loss: 1.535..  Train_Acc: 0.322..  Val Loss: 1.529..  Val_Acc: 0.315\n",
            "Epoch: 21/1000..  Train Loss: 1.539..  Train_Acc: 0.318..  Val Loss: 1.519..  Val_Acc: 0.308\n",
            "Epoch: 22/1000..  Train Loss: 1.534..  Train_Acc: 0.324..  Val Loss: 1.516..  Val_Acc: 0.309\n",
            "Epoch: 23/1000..  Train Loss: 1.533..  Train_Acc: 0.325..  Val Loss: 1.502..  Val_Acc: 0.327\n",
            "Epoch: 24/1000..  Train Loss: 1.525..  Train_Acc: 0.332..  Val Loss: 1.497..  Val_Acc: 0.330\n",
            "Epoch: 25/1000..  Train Loss: 1.525..  Train_Acc: 0.331..  Val Loss: 1.494..  Val_Acc: 0.344\n",
            "Epoch: 26/1000..  Train Loss: 1.521..  Train_Acc: 0.339..  Val Loss: 1.496..  Val_Acc: 0.334\n",
            "Epoch: 27/1000..  Train Loss: 1.522..  Train_Acc: 0.334..  Val Loss: 1.510..  Val_Acc: 0.321\n",
            "Epoch: 28/1000..  Train Loss: 1.528..  Train_Acc: 0.330..  Val Loss: 1.491..  Val_Acc: 0.348\n",
            "Epoch: 29/1000..  Train Loss: 1.516..  Train_Acc: 0.342..  Val Loss: 1.498..  Val_Acc: 0.341\n",
            "Epoch: 30/1000..  Train Loss: 1.513..  Train_Acc: 0.348..  Val Loss: 1.495..  Val_Acc: 0.335\n",
            "Epoch: 31/1000..  Train Loss: 1.516..  Train_Acc: 0.343..  Val Loss: 1.487..  Val_Acc: 0.350\n",
            "Epoch: 32/1000..  Train Loss: 1.514..  Train_Acc: 0.340..  Val Loss: 1.495..  Val_Acc: 0.346\n",
            "Epoch: 33/1000..  Train Loss: 1.512..  Train_Acc: 0.345..  Val Loss: 1.488..  Val_Acc: 0.350\n",
            "Epoch: 34/1000..  Train Loss: 1.513..  Train_Acc: 0.341..  Val Loss: 1.486..  Val_Acc: 0.352\n",
            "Epoch: 35/1000..  Train Loss: 1.510..  Train_Acc: 0.351..  Val Loss: 1.526..  Val_Acc: 0.318\n",
            "Epoch: 36/1000..  Train Loss: 1.512..  Train_Acc: 0.342..  Val Loss: 1.486..  Val_Acc: 0.352\n",
            "Epoch: 37/1000..  Train Loss: 1.508..  Train_Acc: 0.346..  Val Loss: 1.495..  Val_Acc: 0.342\n",
            "Epoch: 38/1000..  Train Loss: 1.516..  Train_Acc: 0.341..  Val Loss: 1.477..  Val_Acc: 0.357\n",
            "Epoch: 39/1000..  Train Loss: 1.500..  Train_Acc: 0.361..  Val Loss: 1.485..  Val_Acc: 0.356\n",
            "Epoch: 40/1000..  Train Loss: 1.513..  Train_Acc: 0.346..  Val Loss: 1.487..  Val_Acc: 0.348\n",
            "Epoch: 41/1000..  Train Loss: 1.502..  Train_Acc: 0.358..  Val Loss: 1.489..  Val_Acc: 0.352\n",
            "Epoch: 42/1000..  Train Loss: 1.505..  Train_Acc: 0.354..  Val Loss: 1.476..  Val_Acc: 0.351\n",
            "Epoch: 43/1000..  Train Loss: 1.498..  Train_Acc: 0.358..  Val Loss: 1.479..  Val_Acc: 0.361\n",
            "Epoch: 44/1000..  Train Loss: 1.501..  Train_Acc: 0.364..  Val Loss: 1.479..  Val_Acc: 0.355\n",
            "Epoch: 45/1000..  Train Loss: 1.506..  Train_Acc: 0.350..  Val Loss: 1.479..  Val_Acc: 0.359\n",
            "Epoch: 46/1000..  Train Loss: 1.494..  Train_Acc: 0.363..  Val Loss: 1.480..  Val_Acc: 0.361\n",
            "Epoch: 47/1000..  Train Loss: 1.492..  Train_Acc: 0.363..  Val Loss: 1.479..  Val_Acc: 0.353\n",
            "Epoch: 48/1000..  Train Loss: 1.490..  Train_Acc: 0.367..  Val Loss: 1.480..  Val_Acc: 0.368\n",
            "Epoch: 49/1000..  Train Loss: 1.498..  Train_Acc: 0.354..  Val Loss: 1.478..  Val_Acc: 0.359\n",
            "Epoch: 50/1000..  Train Loss: 1.492..  Train_Acc: 0.368..  Val Loss: 1.487..  Val_Acc: 0.355\n",
            "Epoch: 51/1000..  Train Loss: 1.495..  Train_Acc: 0.364..  Val Loss: 1.483..  Val_Acc: 0.362\n",
            "Epoch: 52/1000..  Train Loss: 1.498..  Train_Acc: 0.363..  Val Loss: 1.471..  Val_Acc: 0.363\n",
            "Epoch: 53/1000..  Train Loss: 1.492..  Train_Acc: 0.360..  Val Loss: 1.470..  Val_Acc: 0.373\n",
            "Epoch: 54/1000..  Train Loss: 1.488..  Train_Acc: 0.371..  Val Loss: 1.470..  Val_Acc: 0.380\n",
            "Epoch: 55/1000..  Train Loss: 1.495..  Train_Acc: 0.363..  Val Loss: 1.485..  Val_Acc: 0.368\n",
            "Epoch: 56/1000..  Train Loss: 1.490..  Train_Acc: 0.367..  Val Loss: 1.484..  Val_Acc: 0.354\n",
            "Epoch: 57/1000..  Train Loss: 1.485..  Train_Acc: 0.374..  Val Loss: 1.466..  Val_Acc: 0.373\n",
            "Epoch: 58/1000..  Train Loss: 1.490..  Train_Acc: 0.367..  Val Loss: 1.476..  Val_Acc: 0.373\n",
            "Epoch: 59/1000..  Train Loss: 1.483..  Train_Acc: 0.375..  Val Loss: 1.465..  Val_Acc: 0.380\n",
            "Epoch: 60/1000..  Train Loss: 1.489..  Train_Acc: 0.367..  Val Loss: 1.478..  Val_Acc: 0.373\n",
            "Epoch: 61/1000..  Train Loss: 1.480..  Train_Acc: 0.375..  Val Loss: 1.469..  Val_Acc: 0.382\n",
            "Epoch: 62/1000..  Train Loss: 1.479..  Train_Acc: 0.377..  Val Loss: 1.475..  Val_Acc: 0.371\n",
            "Epoch: 63/1000..  Train Loss: 1.493..  Train_Acc: 0.365..  Val Loss: 1.509..  Val_Acc: 0.338\n",
            "Epoch: 64/1000..  Train Loss: 1.485..  Train_Acc: 0.372..  Val Loss: 1.470..  Val_Acc: 0.366\n",
            "Epoch: 65/1000..  Train Loss: 1.478..  Train_Acc: 0.375..  Val Loss: 1.485..  Val_Acc: 0.359\n",
            "Epoch: 66/1000..  Train Loss: 1.478..  Train_Acc: 0.377..  Val Loss: 1.457..  Val_Acc: 0.381\n",
            "Epoch: 67/1000..  Train Loss: 1.474..  Train_Acc: 0.389..  Val Loss: 1.466..  Val_Acc: 0.375\n",
            "Epoch: 68/1000..  Train Loss: 1.481..  Train_Acc: 0.378..  Val Loss: 1.472..  Val_Acc: 0.366\n",
            "Epoch: 69/1000..  Train Loss: 1.484..  Train_Acc: 0.377..  Val Loss: 1.465..  Val_Acc: 0.371\n",
            "Epoch: 70/1000..  Train Loss: 1.480..  Train_Acc: 0.380..  Val Loss: 1.487..  Val_Acc: 0.366\n",
            "Epoch: 71/1000..  Train Loss: 1.482..  Train_Acc: 0.378..  Val Loss: 1.477..  Val_Acc: 0.374\n",
            "Epoch: 72/1000..  Train Loss: 1.474..  Train_Acc: 0.385..  Val Loss: 1.458..  Val_Acc: 0.383\n",
            "Epoch: 73/1000..  Train Loss: 1.475..  Train_Acc: 0.384..  Val Loss: 1.468..  Val_Acc: 0.369\n",
            "Epoch: 74/1000..  Train Loss: 1.474..  Train_Acc: 0.389..  Val Loss: 1.463..  Val_Acc: 0.372\n",
            "Epoch: 75/1000..  Train Loss: 1.482..  Train_Acc: 0.371..  Val Loss: 1.498..  Val_Acc: 0.349\n",
            "Epoch: 76/1000..  Train Loss: 1.487..  Train_Acc: 0.376..  Val Loss: 1.492..  Val_Acc: 0.363\n",
            "Epoch: 77/1000..  Train Loss: 1.475..  Train_Acc: 0.384..  Val Loss: 1.462..  Val_Acc: 0.388\n",
            "Epoch: 78/1000..  Train Loss: 1.474..  Train_Acc: 0.385..  Val Loss: 1.466..  Val_Acc: 0.383\n",
            "Epoch: 79/1000..  Train Loss: 1.470..  Train_Acc: 0.397..  Val Loss: 1.462..  Val_Acc: 0.383\n",
            "Epoch: 80/1000..  Train Loss: 1.472..  Train_Acc: 0.385..  Val Loss: 1.467..  Val_Acc: 0.388\n",
            "Epoch: 81/1000..  Train Loss: 1.469..  Train_Acc: 0.392..  Val Loss: 1.466..  Val_Acc: 0.381\n",
            "Epoch: 82/1000..  Train Loss: 1.472..  Train_Acc: 0.392..  Val Loss: 1.461..  Val_Acc: 0.383\n",
            "Epoch: 83/1000..  Train Loss: 1.469..  Train_Acc: 0.388..  Val Loss: 1.451..  Val_Acc: 0.392\n",
            "Epoch: 84/1000..  Train Loss: 1.465..  Train_Acc: 0.397..  Val Loss: 1.462..  Val_Acc: 0.380\n",
            "Epoch: 85/1000..  Train Loss: 1.470..  Train_Acc: 0.392..  Val Loss: 1.469..  Val_Acc: 0.371\n",
            "Epoch: 86/1000..  Train Loss: 1.471..  Train_Acc: 0.391..  Val Loss: 1.467..  Val_Acc: 0.384\n",
            "Epoch: 87/1000..  Train Loss: 1.476..  Train_Acc: 0.385..  Val Loss: 1.450..  Val_Acc: 0.387\n",
            "Epoch: 88/1000..  Train Loss: 1.474..  Train_Acc: 0.385..  Val Loss: 1.466..  Val_Acc: 0.378\n",
            "Epoch: 89/1000..  Train Loss: 1.467..  Train_Acc: 0.398..  Val Loss: 1.468..  Val_Acc: 0.373\n",
            "Epoch: 90/1000..  Train Loss: 1.468..  Train_Acc: 0.398..  Val Loss: 1.465..  Val_Acc: 0.383\n",
            "Epoch: 91/1000..  Train Loss: 1.476..  Train_Acc: 0.384..  Val Loss: 1.458..  Val_Acc: 0.380\n",
            "Epoch: 92/1000..  Train Loss: 1.466..  Train_Acc: 0.395..  Val Loss: 1.462..  Val_Acc: 0.384\n",
            "Epoch: 93/1000..  Train Loss: 1.465..  Train_Acc: 0.394..  Val Loss: 1.458..  Val_Acc: 0.390\n",
            "Epoch: 94/1000..  Train Loss: 1.463..  Train_Acc: 0.399..  Val Loss: 1.458..  Val_Acc: 0.373\n",
            "Epoch: 95/1000..  Train Loss: 1.463..  Train_Acc: 0.396..  Val Loss: 1.465..  Val_Acc: 0.377\n",
            "Epoch: 96/1000..  Train Loss: 1.467..  Train_Acc: 0.396..  Val Loss: 1.461..  Val_Acc: 0.385\n",
            "Epoch: 97/1000..  Train Loss: 1.462..  Train_Acc: 0.399..  Val Loss: 1.460..  Val_Acc: 0.375\n",
            "Epoch: 98/1000..  Train Loss: 1.460..  Train_Acc: 0.405..  Val Loss: 1.460..  Val_Acc: 0.376\n",
            "Epoch: 99/1000..  Train Loss: 1.467..  Train_Acc: 0.394..  Val Loss: 1.487..  Val_Acc: 0.358\n",
            "Epoch: 100/1000..  Train Loss: 1.471..  Train_Acc: 0.392..  Val Loss: 1.453..  Val_Acc: 0.384\n",
            "Epoch: 101/1000..  Train Loss: 1.456..  Train_Acc: 0.402..  Val Loss: 1.461..  Val_Acc: 0.380\n",
            "Epoch: 102/1000..  Train Loss: 1.464..  Train_Acc: 0.397..  Val Loss: 1.461..  Val_Acc: 0.380\n",
            "Epoch: 103/1000..  Train Loss: 1.464..  Train_Acc: 0.398..  Val Loss: 1.458..  Val_Acc: 0.388\n",
            "Epoch: 104/1000..  Train Loss: 1.459..  Train_Acc: 0.398..  Val Loss: 1.455..  Val_Acc: 0.386\n",
            "Epoch: 105/1000..  Train Loss: 1.464..  Train_Acc: 0.398..  Val Loss: 1.461..  Val_Acc: 0.373\n",
            "Epoch: 106/1000..  Train Loss: 1.456..  Train_Acc: 0.404..  Val Loss: 1.451..  Val_Acc: 0.390\n",
            "Epoch: 107/1000..  Train Loss: 1.459..  Train_Acc: 0.404..  Val Loss: 1.459..  Val_Acc: 0.381\n",
            "Epoch: 108/1000..  Train Loss: 1.460..  Train_Acc: 0.396..  Val Loss: 1.453..  Val_Acc: 0.379\n",
            "Epoch: 109/1000..  Train Loss: 1.458..  Train_Acc: 0.401..  Val Loss: 1.468..  Val_Acc: 0.373\n",
            "Epoch: 110/1000..  Train Loss: 1.459..  Train_Acc: 0.395..  Val Loss: 1.459..  Val_Acc: 0.380\n",
            "Epoch: 111/1000..  Train Loss: 1.460..  Train_Acc: 0.402..  Val Loss: 1.463..  Val_Acc: 0.369\n",
            "Epoch: 112/1000..  Train Loss: 1.455..  Train_Acc: 0.409..  Val Loss: 1.462..  Val_Acc: 0.370\n",
            "Epoch: 113/1000..  Train Loss: 1.453..  Train_Acc: 0.406..  Val Loss: 1.460..  Val_Acc: 0.377\n",
            "Epoch: 114/1000..  Train Loss: 1.451..  Train_Acc: 0.408..  Val Loss: 1.459..  Val_Acc: 0.377\n",
            "Epoch: 115/1000..  Train Loss: 1.459..  Train_Acc: 0.404..  Val Loss: 1.459..  Val_Acc: 0.375\n",
            "Epoch: 116/1000..  Train Loss: 1.452..  Train_Acc: 0.408..  Val Loss: 1.456..  Val_Acc: 0.380\n",
            "Epoch: 117/1000..  Train Loss: 1.455..  Train_Acc: 0.402..  Val Loss: 1.478..  Val_Acc: 0.366\n",
            "Epoch: 118/1000..  Train Loss: 1.455..  Train_Acc: 0.397..  Val Loss: 1.472..  Val_Acc: 0.370\n",
            "Epoch: 119/1000..  Train Loss: 1.446..  Train_Acc: 0.411..  Val Loss: 1.459..  Val_Acc: 0.384\n",
            "Epoch: 120/1000..  Train Loss: 1.463..  Train_Acc: 0.396..  Val Loss: 1.464..  Val_Acc: 0.384\n",
            "Epoch: 121/1000..  Train Loss: 1.453..  Train_Acc: 0.407..  Val Loss: 1.463..  Val_Acc: 0.375\n",
            "Epoch: 122/1000..  Train Loss: 1.452..  Train_Acc: 0.406..  Val Loss: 1.474..  Val_Acc: 0.375\n",
            "Epoch: 123/1000..  Train Loss: 1.457..  Train_Acc: 0.404..  Val Loss: 1.456..  Val_Acc: 0.382\n",
            "Epoch: 124/1000..  Train Loss: 1.447..  Train_Acc: 0.419..  Val Loss: 1.485..  Val_Acc: 0.366\n",
            "Epoch: 125/1000..  Train Loss: 1.451..  Train_Acc: 0.410..  Val Loss: 1.469..  Val_Acc: 0.371\n",
            "Epoch: 126/1000..  Train Loss: 1.444..  Train_Acc: 0.414..  Val Loss: 1.459..  Val_Acc: 0.380\n",
            "Epoch: 127/1000..  Train Loss: 1.454..  Train_Acc: 0.405..  Val Loss: 1.475..  Val_Acc: 0.361\n",
            "Epoch: 128/1000..  Train Loss: 1.448..  Train_Acc: 0.409..  Val Loss: 1.470..  Val_Acc: 0.373\n",
            "Epoch: 129/1000..  Train Loss: 1.446..  Train_Acc: 0.418..  Val Loss: 1.474..  Val_Acc: 0.368\n",
            "Epoch: 130/1000..  Train Loss: 1.437..  Train_Acc: 0.425..  Val Loss: 1.453..  Val_Acc: 0.383\n",
            "Epoch: 131/1000..  Train Loss: 1.446..  Train_Acc: 0.410..  Val Loss: 1.457..  Val_Acc: 0.384\n",
            "Epoch: 132/1000..  Train Loss: 1.442..  Train_Acc: 0.423..  Val Loss: 1.473..  Val_Acc: 0.369\n",
            "Epoch: 133/1000..  Train Loss: 1.442..  Train_Acc: 0.416..  Val Loss: 1.458..  Val_Acc: 0.377\n",
            "Epoch: 134/1000..  Train Loss: 1.445..  Train_Acc: 0.413..  Val Loss: 1.471..  Val_Acc: 0.381\n",
            "Epoch: 135/1000..  Train Loss: 1.448..  Train_Acc: 0.413..  Val Loss: 1.469..  Val_Acc: 0.373\n",
            "Epoch: 136/1000..  Train Loss: 1.446..  Train_Acc: 0.413..  Val Loss: 1.477..  Val_Acc: 0.375\n",
            "Epoch: 137/1000..  Train Loss: 1.440..  Train_Acc: 0.416..  Val Loss: 1.451..  Val_Acc: 0.391\n",
            "Epoch: 138/1000..  Train Loss: 1.438..  Train_Acc: 0.416..  Val Loss: 1.464..  Val_Acc: 0.375\n",
            "Epoch: 139/1000..  Train Loss: 1.442..  Train_Acc: 0.415..  Val Loss: 1.467..  Val_Acc: 0.377\n",
            "Epoch: 140/1000..  Train Loss: 1.433..  Train_Acc: 0.428..  Val Loss: 1.455..  Val_Acc: 0.384\n",
            "Epoch: 141/1000..  Train Loss: 1.438..  Train_Acc: 0.424..  Val Loss: 1.456..  Val_Acc: 0.380\n",
            "Epoch: 142/1000..  Train Loss: 1.435..  Train_Acc: 0.426..  Val Loss: 1.471..  Val_Acc: 0.370\n",
            "Epoch: 143/1000..  Train Loss: 1.440..  Train_Acc: 0.419..  Val Loss: 1.453..  Val_Acc: 0.387\n",
            "Epoch: 144/1000..  Train Loss: 1.434..  Train_Acc: 0.428..  Val Loss: 1.481..  Val_Acc: 0.366\n",
            "Epoch: 145/1000..  Train Loss: 1.436..  Train_Acc: 0.430..  Val Loss: 1.472..  Val_Acc: 0.373\n",
            "Epoch: 146/1000..  Train Loss: 1.436..  Train_Acc: 0.423..  Val Loss: 1.455..  Val_Acc: 0.380\n",
            "Epoch: 147/1000..  Train Loss: 1.433..  Train_Acc: 0.429..  Val Loss: 1.453..  Val_Acc: 0.386\n",
            "Epoch: 148/1000..  Train Loss: 1.436..  Train_Acc: 0.415..  Val Loss: 1.458..  Val_Acc: 0.383\n",
            "Epoch: 149/1000..  Train Loss: 1.432..  Train_Acc: 0.423..  Val Loss: 1.460..  Val_Acc: 0.391\n",
            "Epoch: 150/1000..  Train Loss: 1.433..  Train_Acc: 0.427..  Val Loss: 1.464..  Val_Acc: 0.381\n",
            "Epoch: 151/1000..  Train Loss: 1.439..  Train_Acc: 0.417..  Val Loss: 1.464..  Val_Acc: 0.376\n",
            "Epoch: 152/1000..  Train Loss: 1.436..  Train_Acc: 0.423..  Val Loss: 1.464..  Val_Acc: 0.380\n",
            "Epoch: 153/1000..  Train Loss: 1.442..  Train_Acc: 0.414..  Val Loss: 1.476..  Val_Acc: 0.372\n",
            "Epoch: 154/1000..  Train Loss: 1.431..  Train_Acc: 0.428..  Val Loss: 1.468..  Val_Acc: 0.370\n",
            "Epoch: 155/1000..  Train Loss: 1.432..  Train_Acc: 0.425..  Val Loss: 1.464..  Val_Acc: 0.380\n",
            "Epoch: 156/1000..  Train Loss: 1.429..  Train_Acc: 0.429..  Val Loss: 1.447..  Val_Acc: 0.388\n",
            "Epoch: 157/1000..  Train Loss: 1.432..  Train_Acc: 0.431..  Val Loss: 1.489..  Val_Acc: 0.357\n",
            "Epoch: 158/1000..  Train Loss: 1.433..  Train_Acc: 0.428..  Val Loss: 1.457..  Val_Acc: 0.388\n",
            "Epoch: 159/1000..  Train Loss: 1.430..  Train_Acc: 0.433..  Val Loss: 1.468..  Val_Acc: 0.370\n",
            "Epoch: 160/1000..  Train Loss: 1.433..  Train_Acc: 0.424..  Val Loss: 1.469..  Val_Acc: 0.371\n",
            "Epoch: 161/1000..  Train Loss: 1.434..  Train_Acc: 0.426..  Val Loss: 1.450..  Val_Acc: 0.391\n",
            "Epoch: 162/1000..  Train Loss: 1.429..  Train_Acc: 0.431..  Val Loss: 1.456..  Val_Acc: 0.388\n",
            "Epoch: 163/1000..  Train Loss: 1.429..  Train_Acc: 0.432..  Val Loss: 1.465..  Val_Acc: 0.372\n",
            "Epoch: 164/1000..  Train Loss: 1.425..  Train_Acc: 0.430..  Val Loss: 1.443..  Val_Acc: 0.397\n",
            "Epoch: 165/1000..  Train Loss: 1.423..  Train_Acc: 0.439..  Val Loss: 1.448..  Val_Acc: 0.400\n",
            "Epoch: 166/1000..  Train Loss: 1.418..  Train_Acc: 0.441..  Val Loss: 1.449..  Val_Acc: 0.395\n",
            "Epoch: 167/1000..  Train Loss: 1.424..  Train_Acc: 0.435..  Val Loss: 1.461..  Val_Acc: 0.387\n",
            "Epoch: 168/1000..  Train Loss: 1.421..  Train_Acc: 0.437..  Val Loss: 1.446..  Val_Acc: 0.394\n",
            "Epoch: 169/1000..  Train Loss: 1.418..  Train_Acc: 0.441..  Val Loss: 1.465..  Val_Acc: 0.376\n",
            "Epoch: 170/1000..  Train Loss: 1.422..  Train_Acc: 0.434..  Val Loss: 1.460..  Val_Acc: 0.380\n",
            "Epoch: 171/1000..  Train Loss: 1.416..  Train_Acc: 0.443..  Val Loss: 1.470..  Val_Acc: 0.381\n",
            "Epoch: 172/1000..  Train Loss: 1.427..  Train_Acc: 0.431..  Val Loss: 1.455..  Val_Acc: 0.393\n",
            "Epoch: 173/1000..  Train Loss: 1.422..  Train_Acc: 0.435..  Val Loss: 1.510..  Val_Acc: 0.345\n",
            "Epoch: 174/1000..  Train Loss: 1.429..  Train_Acc: 0.432..  Val Loss: 1.457..  Val_Acc: 0.383\n",
            "Epoch: 175/1000..  Train Loss: 1.422..  Train_Acc: 0.434..  Val Loss: 1.460..  Val_Acc: 0.381\n",
            "Epoch: 176/1000..  Train Loss: 1.420..  Train_Acc: 0.439..  Val Loss: 1.456..  Val_Acc: 0.380\n",
            "Epoch: 177/1000..  Train Loss: 1.437..  Train_Acc: 0.417..  Val Loss: 1.464..  Val_Acc: 0.371\n",
            "Epoch: 178/1000..  Train Loss: 1.414..  Train_Acc: 0.440..  Val Loss: 1.467..  Val_Acc: 0.380\n",
            "Epoch: 179/1000..  Train Loss: 1.410..  Train_Acc: 0.447..  Val Loss: 1.466..  Val_Acc: 0.384\n",
            "Epoch: 180/1000..  Train Loss: 1.414..  Train_Acc: 0.439..  Val Loss: 1.453..  Val_Acc: 0.390\n",
            "Epoch: 181/1000..  Train Loss: 1.413..  Train_Acc: 0.441..  Val Loss: 1.466..  Val_Acc: 0.376\n",
            "Epoch: 182/1000..  Train Loss: 1.412..  Train_Acc: 0.445..  Val Loss: 1.466..  Val_Acc: 0.380\n",
            "Epoch: 183/1000..  Train Loss: 1.413..  Train_Acc: 0.449..  Val Loss: 1.471..  Val_Acc: 0.377\n",
            "Epoch: 184/1000..  Train Loss: 1.422..  Train_Acc: 0.434..  Val Loss: 1.473..  Val_Acc: 0.377\n",
            "Epoch: 185/1000..  Train Loss: 1.407..  Train_Acc: 0.449..  Val Loss: 1.452..  Val_Acc: 0.384\n",
            "Epoch: 186/1000..  Train Loss: 1.412..  Train_Acc: 0.450..  Val Loss: 1.454..  Val_Acc: 0.390\n",
            "Epoch: 187/1000..  Train Loss: 1.411..  Train_Acc: 0.447..  Val Loss: 1.473..  Val_Acc: 0.369\n",
            "Epoch: 188/1000..  Train Loss: 1.406..  Train_Acc: 0.452..  Val Loss: 1.457..  Val_Acc: 0.388\n",
            "Epoch: 189/1000..  Train Loss: 1.401..  Train_Acc: 0.453..  Val Loss: 1.454..  Val_Acc: 0.391\n",
            "Epoch: 190/1000..  Train Loss: 1.408..  Train_Acc: 0.449..  Val Loss: 1.446..  Val_Acc: 0.396\n",
            "Epoch: 191/1000..  Train Loss: 1.405..  Train_Acc: 0.451..  Val Loss: 1.470..  Val_Acc: 0.370\n",
            "Epoch: 192/1000..  Train Loss: 1.414..  Train_Acc: 0.442..  Val Loss: 1.467..  Val_Acc: 0.379\n",
            "Epoch: 193/1000..  Train Loss: 1.396..  Train_Acc: 0.466..  Val Loss: 1.454..  Val_Acc: 0.394\n",
            "Epoch: 194/1000..  Train Loss: 1.404..  Train_Acc: 0.452..  Val Loss: 1.467..  Val_Acc: 0.373\n",
            "Epoch: 195/1000..  Train Loss: 1.416..  Train_Acc: 0.440..  Val Loss: 1.470..  Val_Acc: 0.377\n",
            "Epoch: 196/1000..  Train Loss: 1.410..  Train_Acc: 0.452..  Val Loss: 1.452..  Val_Acc: 0.388\n",
            "Epoch: 197/1000..  Train Loss: 1.399..  Train_Acc: 0.457..  Val Loss: 1.454..  Val_Acc: 0.400\n",
            "Epoch: 198/1000..  Train Loss: 1.403..  Train_Acc: 0.453..  Val Loss: 1.451..  Val_Acc: 0.389\n",
            "Epoch: 199/1000..  Train Loss: 1.405..  Train_Acc: 0.454..  Val Loss: 1.470..  Val_Acc: 0.370\n",
            "Epoch: 200/1000..  Train Loss: 1.398..  Train_Acc: 0.458..  Val Loss: 1.458..  Val_Acc: 0.383\n",
            "Epoch: 201/1000..  Train Loss: 1.400..  Train_Acc: 0.460..  Val Loss: 1.472..  Val_Acc: 0.378\n",
            "Epoch: 202/1000..  Train Loss: 1.392..  Train_Acc: 0.467..  Val Loss: 1.459..  Val_Acc: 0.386\n",
            "Epoch: 203/1000..  Train Loss: 1.399..  Train_Acc: 0.457..  Val Loss: 1.455..  Val_Acc: 0.386\n",
            "Epoch: 204/1000..  Train Loss: 1.400..  Train_Acc: 0.462..  Val Loss: 1.472..  Val_Acc: 0.379\n",
            "Epoch: 205/1000..  Train Loss: 1.402..  Train_Acc: 0.457..  Val Loss: 1.462..  Val_Acc: 0.387\n",
            "Epoch: 206/1000..  Train Loss: 1.405..  Train_Acc: 0.454..  Val Loss: 1.471..  Val_Acc: 0.370\n",
            "Epoch: 207/1000..  Train Loss: 1.396..  Train_Acc: 0.455..  Val Loss: 1.452..  Val_Acc: 0.395\n",
            "Epoch: 208/1000..  Train Loss: 1.395..  Train_Acc: 0.466..  Val Loss: 1.466..  Val_Acc: 0.383\n",
            "Epoch: 209/1000..  Train Loss: 1.404..  Train_Acc: 0.456..  Val Loss: 1.479..  Val_Acc: 0.364\n",
            "Epoch: 210/1000..  Train Loss: 1.400..  Train_Acc: 0.455..  Val Loss: 1.462..  Val_Acc: 0.380\n",
            "Epoch: 211/1000..  Train Loss: 1.393..  Train_Acc: 0.468..  Val Loss: 1.461..  Val_Acc: 0.387\n",
            "Epoch: 212/1000..  Train Loss: 1.404..  Train_Acc: 0.454..  Val Loss: 1.458..  Val_Acc: 0.389\n",
            "Epoch: 213/1000..  Train Loss: 1.399..  Train_Acc: 0.457..  Val Loss: 1.455..  Val_Acc: 0.383\n",
            "Epoch: 214/1000..  Train Loss: 1.399..  Train_Acc: 0.452..  Val Loss: 1.458..  Val_Acc: 0.389\n",
            "Epoch: 215/1000..  Train Loss: 1.394..  Train_Acc: 0.464..  Val Loss: 1.482..  Val_Acc: 0.365\n",
            "Epoch: 216/1000..  Train Loss: 1.393..  Train_Acc: 0.466..  Val Loss: 1.464..  Val_Acc: 0.379\n",
            "Epoch: 217/1000..  Train Loss: 1.400..  Train_Acc: 0.454..  Val Loss: 1.462..  Val_Acc: 0.382\n",
            "Epoch: 218/1000..  Train Loss: 1.395..  Train_Acc: 0.463..  Val Loss: 1.479..  Val_Acc: 0.378\n",
            "Epoch: 219/1000..  Train Loss: 1.386..  Train_Acc: 0.470..  Val Loss: 1.466..  Val_Acc: 0.381\n",
            "Epoch: 220/1000..  Train Loss: 1.384..  Train_Acc: 0.473..  Val Loss: 1.459..  Val_Acc: 0.384\n",
            "Epoch: 221/1000..  Train Loss: 1.390..  Train_Acc: 0.468..  Val Loss: 1.455..  Val_Acc: 0.390\n",
            "Epoch: 222/1000..  Train Loss: 1.386..  Train_Acc: 0.474..  Val Loss: 1.462..  Val_Acc: 0.390\n",
            "Epoch: 223/1000..  Train Loss: 1.388..  Train_Acc: 0.471..  Val Loss: 1.454..  Val_Acc: 0.392\n",
            "Epoch: 224/1000..  Train Loss: 1.392..  Train_Acc: 0.468..  Val Loss: 1.465..  Val_Acc: 0.375\n",
            "Epoch: 225/1000..  Train Loss: 1.389..  Train_Acc: 0.468..  Val Loss: 1.459..  Val_Acc: 0.389\n",
            "Epoch: 226/1000..  Train Loss: 1.389..  Train_Acc: 0.471..  Val Loss: 1.469..  Val_Acc: 0.378\n",
            "Epoch: 227/1000..  Train Loss: 1.387..  Train_Acc: 0.469..  Val Loss: 1.461..  Val_Acc: 0.383\n",
            "Epoch: 228/1000..  Train Loss: 1.386..  Train_Acc: 0.467..  Val Loss: 1.483..  Val_Acc: 0.369\n",
            "Epoch: 229/1000..  Train Loss: 1.385..  Train_Acc: 0.473..  Val Loss: 1.473..  Val_Acc: 0.372\n",
            "Epoch: 230/1000..  Train Loss: 1.385..  Train_Acc: 0.469..  Val Loss: 1.471..  Val_Acc: 0.382\n",
            "Epoch: 231/1000..  Train Loss: 1.401..  Train_Acc: 0.458..  Val Loss: 1.466..  Val_Acc: 0.379\n",
            "Epoch: 232/1000..  Train Loss: 1.387..  Train_Acc: 0.472..  Val Loss: 1.459..  Val_Acc: 0.380\n",
            "Epoch: 233/1000..  Train Loss: 1.386..  Train_Acc: 0.468..  Val Loss: 1.471..  Val_Acc: 0.379\n",
            "Epoch: 234/1000..  Train Loss: 1.390..  Train_Acc: 0.465..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 235/1000..  Train Loss: 1.390..  Train_Acc: 0.463..  Val Loss: 1.458..  Val_Acc: 0.380\n",
            "Epoch: 236/1000..  Train Loss: 1.379..  Train_Acc: 0.476..  Val Loss: 1.466..  Val_Acc: 0.375\n",
            "Epoch: 237/1000..  Train Loss: 1.387..  Train_Acc: 0.471..  Val Loss: 1.474..  Val_Acc: 0.374\n",
            "Epoch: 238/1000..  Train Loss: 1.381..  Train_Acc: 0.474..  Val Loss: 1.467..  Val_Acc: 0.377\n",
            "Epoch: 239/1000..  Train Loss: 1.374..  Train_Acc: 0.485..  Val Loss: 1.475..  Val_Acc: 0.376\n",
            "Epoch: 240/1000..  Train Loss: 1.378..  Train_Acc: 0.479..  Val Loss: 1.472..  Val_Acc: 0.379\n",
            "Epoch: 241/1000..  Train Loss: 1.381..  Train_Acc: 0.471..  Val Loss: 1.474..  Val_Acc: 0.373\n",
            "Epoch: 242/1000..  Train Loss: 1.371..  Train_Acc: 0.487..  Val Loss: 1.473..  Val_Acc: 0.373\n",
            "Epoch: 243/1000..  Train Loss: 1.389..  Train_Acc: 0.468..  Val Loss: 1.463..  Val_Acc: 0.378\n",
            "Epoch: 244/1000..  Train Loss: 1.370..  Train_Acc: 0.490..  Val Loss: 1.471..  Val_Acc: 0.370\n",
            "Epoch: 245/1000..  Train Loss: 1.379..  Train_Acc: 0.478..  Val Loss: 1.472..  Val_Acc: 0.371\n",
            "Epoch: 246/1000..  Train Loss: 1.374..  Train_Acc: 0.480..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 247/1000..  Train Loss: 1.381..  Train_Acc: 0.474..  Val Loss: 1.461..  Val_Acc: 0.382\n",
            "Epoch: 248/1000..  Train Loss: 1.379..  Train_Acc: 0.475..  Val Loss: 1.467..  Val_Acc: 0.382\n",
            "Epoch: 249/1000..  Train Loss: 1.387..  Train_Acc: 0.466..  Val Loss: 1.475..  Val_Acc: 0.374\n",
            "Epoch: 250/1000..  Train Loss: 1.375..  Train_Acc: 0.479..  Val Loss: 1.466..  Val_Acc: 0.381\n",
            "Epoch: 251/1000..  Train Loss: 1.377..  Train_Acc: 0.476..  Val Loss: 1.473..  Val_Acc: 0.369\n",
            "Epoch: 252/1000..  Train Loss: 1.381..  Train_Acc: 0.476..  Val Loss: 1.475..  Val_Acc: 0.374\n",
            "Epoch: 253/1000..  Train Loss: 1.375..  Train_Acc: 0.484..  Val Loss: 1.482..  Val_Acc: 0.366\n",
            "Epoch: 254/1000..  Train Loss: 1.374..  Train_Acc: 0.480..  Val Loss: 1.472..  Val_Acc: 0.374\n",
            "Epoch: 255/1000..  Train Loss: 1.367..  Train_Acc: 0.495..  Val Loss: 1.474..  Val_Acc: 0.375\n",
            "Epoch: 256/1000..  Train Loss: 1.378..  Train_Acc: 0.479..  Val Loss: 1.476..  Val_Acc: 0.374\n",
            "Epoch: 257/1000..  Train Loss: 1.374..  Train_Acc: 0.486..  Val Loss: 1.464..  Val_Acc: 0.384\n",
            "Epoch: 258/1000..  Train Loss: 1.368..  Train_Acc: 0.488..  Val Loss: 1.469..  Val_Acc: 0.377\n",
            "Epoch: 259/1000..  Train Loss: 1.372..  Train_Acc: 0.484..  Val Loss: 1.475..  Val_Acc: 0.367\n",
            "Epoch: 260/1000..  Train Loss: 1.393..  Train_Acc: 0.463..  Val Loss: 1.459..  Val_Acc: 0.385\n",
            "Epoch: 261/1000..  Train Loss: 1.381..  Train_Acc: 0.477..  Val Loss: 1.468..  Val_Acc: 0.386\n",
            "Epoch: 262/1000..  Train Loss: 1.362..  Train_Acc: 0.495..  Val Loss: 1.459..  Val_Acc: 0.379\n",
            "Epoch: 263/1000..  Train Loss: 1.371..  Train_Acc: 0.485..  Val Loss: 1.468..  Val_Acc: 0.373\n",
            "Epoch: 264/1000..  Train Loss: 1.372..  Train_Acc: 0.483..  Val Loss: 1.476..  Val_Acc: 0.368\n",
            "Epoch: 265/1000..  Train Loss: 1.371..  Train_Acc: 0.488..  Val Loss: 1.457..  Val_Acc: 0.384\n",
            "Epoch: 266/1000..  Train Loss: 1.363..  Train_Acc: 0.496..  Val Loss: 1.450..  Val_Acc: 0.394\n",
            "Epoch: 267/1000..  Train Loss: 1.365..  Train_Acc: 0.492..  Val Loss: 1.487..  Val_Acc: 0.369\n",
            "Epoch: 268/1000..  Train Loss: 1.361..  Train_Acc: 0.498..  Val Loss: 1.468..  Val_Acc: 0.380\n",
            "Epoch: 269/1000..  Train Loss: 1.369..  Train_Acc: 0.489..  Val Loss: 1.468..  Val_Acc: 0.376\n",
            "Epoch: 270/1000..  Train Loss: 1.367..  Train_Acc: 0.489..  Val Loss: 1.472..  Val_Acc: 0.377\n",
            "Epoch: 271/1000..  Train Loss: 1.353..  Train_Acc: 0.501..  Val Loss: 1.470..  Val_Acc: 0.379\n",
            "Epoch: 272/1000..  Train Loss: 1.357..  Train_Acc: 0.503..  Val Loss: 1.470..  Val_Acc: 0.380\n",
            "Epoch: 273/1000..  Train Loss: 1.370..  Train_Acc: 0.480..  Val Loss: 1.483..  Val_Acc: 0.366\n",
            "Epoch: 274/1000..  Train Loss: 1.364..  Train_Acc: 0.494..  Val Loss: 1.467..  Val_Acc: 0.377\n",
            "Epoch: 275/1000..  Train Loss: 1.375..  Train_Acc: 0.485..  Val Loss: 1.470..  Val_Acc: 0.379\n",
            "Epoch: 276/1000..  Train Loss: 1.371..  Train_Acc: 0.483..  Val Loss: 1.462..  Val_Acc: 0.381\n",
            "Epoch: 277/1000..  Train Loss: 1.371..  Train_Acc: 0.480..  Val Loss: 1.451..  Val_Acc: 0.398\n",
            "Epoch: 278/1000..  Train Loss: 1.357..  Train_Acc: 0.502..  Val Loss: 1.463..  Val_Acc: 0.381\n",
            "Epoch: 279/1000..  Train Loss: 1.361..  Train_Acc: 0.493..  Val Loss: 1.460..  Val_Acc: 0.388\n",
            "Epoch: 280/1000..  Train Loss: 1.354..  Train_Acc: 0.503..  Val Loss: 1.472..  Val_Acc: 0.387\n",
            "Epoch: 281/1000..  Train Loss: 1.356..  Train_Acc: 0.499..  Val Loss: 1.478..  Val_Acc: 0.373\n",
            "Epoch: 282/1000..  Train Loss: 1.356..  Train_Acc: 0.501..  Val Loss: 1.461..  Val_Acc: 0.384\n",
            "Epoch: 283/1000..  Train Loss: 1.361..  Train_Acc: 0.490..  Val Loss: 1.468..  Val_Acc: 0.377\n",
            "Epoch: 284/1000..  Train Loss: 1.358..  Train_Acc: 0.500..  Val Loss: 1.465..  Val_Acc: 0.374\n",
            "Epoch: 285/1000..  Train Loss: 1.349..  Train_Acc: 0.513..  Val Loss: 1.489..  Val_Acc: 0.366\n",
            "Epoch: 286/1000..  Train Loss: 1.356..  Train_Acc: 0.498..  Val Loss: 1.472..  Val_Acc: 0.376\n",
            "Epoch: 287/1000..  Train Loss: 1.357..  Train_Acc: 0.499..  Val Loss: 1.471..  Val_Acc: 0.377\n",
            "Epoch: 288/1000..  Train Loss: 1.349..  Train_Acc: 0.505..  Val Loss: 1.475..  Val_Acc: 0.370\n",
            "Epoch: 289/1000..  Train Loss: 1.349..  Train_Acc: 0.507..  Val Loss: 1.462..  Val_Acc: 0.386\n",
            "Epoch: 290/1000..  Train Loss: 1.352..  Train_Acc: 0.501..  Val Loss: 1.480..  Val_Acc: 0.370\n",
            "Epoch: 291/1000..  Train Loss: 1.351..  Train_Acc: 0.507..  Val Loss: 1.472..  Val_Acc: 0.377\n",
            "Epoch: 292/1000..  Train Loss: 1.350..  Train_Acc: 0.505..  Val Loss: 1.459..  Val_Acc: 0.382\n",
            "Epoch: 293/1000..  Train Loss: 1.358..  Train_Acc: 0.499..  Val Loss: 1.475..  Val_Acc: 0.366\n",
            "Epoch: 294/1000..  Train Loss: 1.353..  Train_Acc: 0.502..  Val Loss: 1.469..  Val_Acc: 0.383\n",
            "Epoch: 295/1000..  Train Loss: 1.351..  Train_Acc: 0.503..  Val Loss: 1.466..  Val_Acc: 0.377\n",
            "Epoch: 296/1000..  Train Loss: 1.349..  Train_Acc: 0.506..  Val Loss: 1.470..  Val_Acc: 0.373\n",
            "Epoch: 297/1000..  Train Loss: 1.353..  Train_Acc: 0.503..  Val Loss: 1.462..  Val_Acc: 0.385\n",
            "Epoch: 298/1000..  Train Loss: 1.348..  Train_Acc: 0.505..  Val Loss: 1.473..  Val_Acc: 0.381\n",
            "Epoch: 299/1000..  Train Loss: 1.344..  Train_Acc: 0.511..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 300/1000..  Train Loss: 1.354..  Train_Acc: 0.504..  Val Loss: 1.457..  Val_Acc: 0.385\n",
            "Epoch: 301/1000..  Train Loss: 1.358..  Train_Acc: 0.500..  Val Loss: 1.462..  Val_Acc: 0.378\n",
            "Epoch: 302/1000..  Train Loss: 1.345..  Train_Acc: 0.511..  Val Loss: 1.474..  Val_Acc: 0.373\n",
            "Epoch: 303/1000..  Train Loss: 1.355..  Train_Acc: 0.497..  Val Loss: 1.489..  Val_Acc: 0.364\n",
            "Epoch: 304/1000..  Train Loss: 1.351..  Train_Acc: 0.500..  Val Loss: 1.463..  Val_Acc: 0.389\n",
            "Epoch: 305/1000..  Train Loss: 1.349..  Train_Acc: 0.508..  Val Loss: 1.465..  Val_Acc: 0.384\n",
            "Epoch: 306/1000..  Train Loss: 1.342..  Train_Acc: 0.510..  Val Loss: 1.466..  Val_Acc: 0.376\n",
            "Epoch: 307/1000..  Train Loss: 1.344..  Train_Acc: 0.510..  Val Loss: 1.473..  Val_Acc: 0.378\n",
            "Epoch: 308/1000..  Train Loss: 1.348..  Train_Acc: 0.504..  Val Loss: 1.455..  Val_Acc: 0.387\n",
            "Epoch: 309/1000..  Train Loss: 1.347..  Train_Acc: 0.508..  Val Loss: 1.475..  Val_Acc: 0.377\n",
            "Epoch: 310/1000..  Train Loss: 1.345..  Train_Acc: 0.504..  Val Loss: 1.460..  Val_Acc: 0.388\n",
            "Epoch: 311/1000..  Train Loss: 1.346..  Train_Acc: 0.509..  Val Loss: 1.475..  Val_Acc: 0.377\n",
            "Epoch: 312/1000..  Train Loss: 1.340..  Train_Acc: 0.516..  Val Loss: 1.476..  Val_Acc: 0.380\n",
            "Epoch: 313/1000..  Train Loss: 1.339..  Train_Acc: 0.520..  Val Loss: 1.469..  Val_Acc: 0.380\n",
            "Epoch: 314/1000..  Train Loss: 1.336..  Train_Acc: 0.519..  Val Loss: 1.463..  Val_Acc: 0.382\n",
            "Epoch: 315/1000..  Train Loss: 1.337..  Train_Acc: 0.522..  Val Loss: 1.473..  Val_Acc: 0.380\n",
            "Epoch: 316/1000..  Train Loss: 1.345..  Train_Acc: 0.509..  Val Loss: 1.496..  Val_Acc: 0.364\n",
            "Epoch: 317/1000..  Train Loss: 1.341..  Train_Acc: 0.516..  Val Loss: 1.464..  Val_Acc: 0.388\n",
            "Epoch: 318/1000..  Train Loss: 1.336..  Train_Acc: 0.517..  Val Loss: 1.470..  Val_Acc: 0.392\n",
            "Epoch: 319/1000..  Train Loss: 1.339..  Train_Acc: 0.513..  Val Loss: 1.490..  Val_Acc: 0.365\n",
            "Epoch: 320/1000..  Train Loss: 1.339..  Train_Acc: 0.517..  Val Loss: 1.462..  Val_Acc: 0.388\n",
            "Epoch: 321/1000..  Train Loss: 1.337..  Train_Acc: 0.515..  Val Loss: 1.474..  Val_Acc: 0.376\n",
            "Epoch: 322/1000..  Train Loss: 1.340..  Train_Acc: 0.516..  Val Loss: 1.469..  Val_Acc: 0.380\n",
            "Epoch: 323/1000..  Train Loss: 1.342..  Train_Acc: 0.512..  Val Loss: 1.471..  Val_Acc: 0.385\n",
            "Epoch: 324/1000..  Train Loss: 1.338..  Train_Acc: 0.518..  Val Loss: 1.490..  Val_Acc: 0.368\n",
            "Epoch: 325/1000..  Train Loss: 1.343..  Train_Acc: 0.509..  Val Loss: 1.470..  Val_Acc: 0.377\n",
            "Epoch: 326/1000..  Train Loss: 1.340..  Train_Acc: 0.519..  Val Loss: 1.470..  Val_Acc: 0.381\n",
            "Epoch: 327/1000..  Train Loss: 1.334..  Train_Acc: 0.524..  Val Loss: 1.462..  Val_Acc: 0.383\n",
            "Epoch: 328/1000..  Train Loss: 1.338..  Train_Acc: 0.519..  Val Loss: 1.477..  Val_Acc: 0.377\n",
            "Epoch: 329/1000..  Train Loss: 1.336..  Train_Acc: 0.518..  Val Loss: 1.465..  Val_Acc: 0.381\n",
            "Epoch: 330/1000..  Train Loss: 1.334..  Train_Acc: 0.520..  Val Loss: 1.474..  Val_Acc: 0.371\n",
            "Epoch: 331/1000..  Train Loss: 1.344..  Train_Acc: 0.507..  Val Loss: 1.462..  Val_Acc: 0.389\n",
            "Epoch: 332/1000..  Train Loss: 1.327..  Train_Acc: 0.531..  Val Loss: 1.473..  Val_Acc: 0.374\n",
            "Epoch: 333/1000..  Train Loss: 1.330..  Train_Acc: 0.529..  Val Loss: 1.468..  Val_Acc: 0.380\n",
            "Epoch: 334/1000..  Train Loss: 1.334..  Train_Acc: 0.526..  Val Loss: 1.485..  Val_Acc: 0.367\n",
            "Epoch: 335/1000..  Train Loss: 1.330..  Train_Acc: 0.527..  Val Loss: 1.481..  Val_Acc: 0.370\n",
            "Epoch: 336/1000..  Train Loss: 1.332..  Train_Acc: 0.526..  Val Loss: 1.484..  Val_Acc: 0.370\n",
            "Epoch: 337/1000..  Train Loss: 1.340..  Train_Acc: 0.510..  Val Loss: 1.466..  Val_Acc: 0.380\n",
            "Epoch: 338/1000..  Train Loss: 1.333..  Train_Acc: 0.525..  Val Loss: 1.470..  Val_Acc: 0.376\n",
            "Epoch: 339/1000..  Train Loss: 1.330..  Train_Acc: 0.526..  Val Loss: 1.466..  Val_Acc: 0.386\n",
            "Epoch: 340/1000..  Train Loss: 1.319..  Train_Acc: 0.536..  Val Loss: 1.475..  Val_Acc: 0.379\n",
            "Epoch: 341/1000..  Train Loss: 1.336..  Train_Acc: 0.517..  Val Loss: 1.485..  Val_Acc: 0.370\n",
            "Epoch: 342/1000..  Train Loss: 1.332..  Train_Acc: 0.527..  Val Loss: 1.482..  Val_Acc: 0.370\n",
            "Epoch: 343/1000..  Train Loss: 1.336..  Train_Acc: 0.521..  Val Loss: 1.469..  Val_Acc: 0.383\n",
            "Epoch: 344/1000..  Train Loss: 1.329..  Train_Acc: 0.525..  Val Loss: 1.463..  Val_Acc: 0.381\n",
            "Epoch: 345/1000..  Train Loss: 1.328..  Train_Acc: 0.527..  Val Loss: 1.475..  Val_Acc: 0.379\n",
            "Epoch: 346/1000..  Train Loss: 1.330..  Train_Acc: 0.524..  Val Loss: 1.473..  Val_Acc: 0.380\n",
            "Epoch: 347/1000..  Train Loss: 1.322..  Train_Acc: 0.537..  Val Loss: 1.478..  Val_Acc: 0.376\n",
            "Epoch: 348/1000..  Train Loss: 1.325..  Train_Acc: 0.534..  Val Loss: 1.483..  Val_Acc: 0.371\n",
            "Epoch: 349/1000..  Train Loss: 1.338..  Train_Acc: 0.516..  Val Loss: 1.465..  Val_Acc: 0.380\n",
            "Epoch: 350/1000..  Train Loss: 1.323..  Train_Acc: 0.531..  Val Loss: 1.475..  Val_Acc: 0.376\n",
            "Epoch: 351/1000..  Train Loss: 1.321..  Train_Acc: 0.534..  Val Loss: 1.482..  Val_Acc: 0.362\n",
            "Epoch: 352/1000..  Train Loss: 1.322..  Train_Acc: 0.534..  Val Loss: 1.477..  Val_Acc: 0.371\n",
            "Epoch: 353/1000..  Train Loss: 1.318..  Train_Acc: 0.545..  Val Loss: 1.478..  Val_Acc: 0.364\n",
            "Epoch: 354/1000..  Train Loss: 1.323..  Train_Acc: 0.532..  Val Loss: 1.475..  Val_Acc: 0.370\n",
            "Epoch: 355/1000..  Train Loss: 1.320..  Train_Acc: 0.537..  Val Loss: 1.482..  Val_Acc: 0.371\n",
            "Epoch: 356/1000..  Train Loss: 1.322..  Train_Acc: 0.534..  Val Loss: 1.487..  Val_Acc: 0.362\n",
            "Epoch: 357/1000..  Train Loss: 1.321..  Train_Acc: 0.530..  Val Loss: 1.513..  Val_Acc: 0.345\n",
            "Epoch: 358/1000..  Train Loss: 1.320..  Train_Acc: 0.541..  Val Loss: 1.466..  Val_Acc: 0.375\n",
            "Epoch: 359/1000..  Train Loss: 1.327..  Train_Acc: 0.528..  Val Loss: 1.471..  Val_Acc: 0.373\n",
            "Epoch: 360/1000..  Train Loss: 1.324..  Train_Acc: 0.532..  Val Loss: 1.478..  Val_Acc: 0.371\n",
            "Epoch: 361/1000..  Train Loss: 1.312..  Train_Acc: 0.546..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 362/1000..  Train Loss: 1.320..  Train_Acc: 0.534..  Val Loss: 1.493..  Val_Acc: 0.356\n",
            "Epoch: 363/1000..  Train Loss: 1.321..  Train_Acc: 0.535..  Val Loss: 1.486..  Val_Acc: 0.366\n",
            "Epoch: 364/1000..  Train Loss: 1.315..  Train_Acc: 0.540..  Val Loss: 1.484..  Val_Acc: 0.362\n",
            "Epoch: 365/1000..  Train Loss: 1.319..  Train_Acc: 0.531..  Val Loss: 1.481..  Val_Acc: 0.367\n",
            "Epoch: 366/1000..  Train Loss: 1.314..  Train_Acc: 0.538..  Val Loss: 1.489..  Val_Acc: 0.363\n",
            "Epoch: 367/1000..  Train Loss: 1.308..  Train_Acc: 0.546..  Val Loss: 1.483..  Val_Acc: 0.361\n",
            "Epoch: 368/1000..  Train Loss: 1.328..  Train_Acc: 0.526..  Val Loss: 1.490..  Val_Acc: 0.355\n",
            "Epoch: 369/1000..  Train Loss: 1.316..  Train_Acc: 0.539..  Val Loss: 1.477..  Val_Acc: 0.372\n",
            "Epoch: 370/1000..  Train Loss: 1.310..  Train_Acc: 0.549..  Val Loss: 1.465..  Val_Acc: 0.380\n",
            "Epoch: 371/1000..  Train Loss: 1.310..  Train_Acc: 0.544..  Val Loss: 1.477..  Val_Acc: 0.374\n",
            "Epoch: 372/1000..  Train Loss: 1.309..  Train_Acc: 0.545..  Val Loss: 1.458..  Val_Acc: 0.384\n",
            "Epoch: 373/1000..  Train Loss: 1.318..  Train_Acc: 0.538..  Val Loss: 1.456..  Val_Acc: 0.388\n",
            "Epoch: 374/1000..  Train Loss: 1.319..  Train_Acc: 0.539..  Val Loss: 1.470..  Val_Acc: 0.380\n",
            "Epoch: 375/1000..  Train Loss: 1.318..  Train_Acc: 0.540..  Val Loss: 1.488..  Val_Acc: 0.361\n",
            "Epoch: 376/1000..  Train Loss: 1.313..  Train_Acc: 0.537..  Val Loss: 1.488..  Val_Acc: 0.366\n",
            "Epoch: 377/1000..  Train Loss: 1.318..  Train_Acc: 0.531..  Val Loss: 1.482..  Val_Acc: 0.368\n",
            "Epoch: 378/1000..  Train Loss: 1.311..  Train_Acc: 0.542..  Val Loss: 1.472..  Val_Acc: 0.373\n",
            "Epoch: 379/1000..  Train Loss: 1.313..  Train_Acc: 0.539..  Val Loss: 1.489..  Val_Acc: 0.362\n",
            "Epoch: 380/1000..  Train Loss: 1.312..  Train_Acc: 0.544..  Val Loss: 1.471..  Val_Acc: 0.372\n",
            "Epoch: 381/1000..  Train Loss: 1.313..  Train_Acc: 0.540..  Val Loss: 1.486..  Val_Acc: 0.367\n",
            "Epoch: 382/1000..  Train Loss: 1.316..  Train_Acc: 0.539..  Val Loss: 1.500..  Val_Acc: 0.356\n",
            "Epoch: 383/1000..  Train Loss: 1.314..  Train_Acc: 0.538..  Val Loss: 1.482..  Val_Acc: 0.366\n",
            "Epoch: 384/1000..  Train Loss: 1.309..  Train_Acc: 0.545..  Val Loss: 1.499..  Val_Acc: 0.348\n",
            "Epoch: 385/1000..  Train Loss: 1.311..  Train_Acc: 0.543..  Val Loss: 1.475..  Val_Acc: 0.366\n",
            "Epoch: 386/1000..  Train Loss: 1.310..  Train_Acc: 0.542..  Val Loss: 1.501..  Val_Acc: 0.360\n",
            "Epoch: 387/1000..  Train Loss: 1.309..  Train_Acc: 0.543..  Val Loss: 1.474..  Val_Acc: 0.377\n",
            "Epoch: 388/1000..  Train Loss: 1.306..  Train_Acc: 0.550..  Val Loss: 1.492..  Val_Acc: 0.352\n",
            "Epoch: 389/1000..  Train Loss: 1.304..  Train_Acc: 0.550..  Val Loss: 1.472..  Val_Acc: 0.369\n",
            "Epoch: 390/1000..  Train Loss: 1.302..  Train_Acc: 0.554..  Val Loss: 1.462..  Val_Acc: 0.381\n",
            "Epoch: 391/1000..  Train Loss: 1.297..  Train_Acc: 0.561..  Val Loss: 1.473..  Val_Acc: 0.374\n",
            "Epoch: 392/1000..  Train Loss: 1.306..  Train_Acc: 0.545..  Val Loss: 1.471..  Val_Acc: 0.372\n",
            "Epoch: 393/1000..  Train Loss: 1.309..  Train_Acc: 0.551..  Val Loss: 1.472..  Val_Acc: 0.376\n",
            "Epoch: 394/1000..  Train Loss: 1.309..  Train_Acc: 0.543..  Val Loss: 1.463..  Val_Acc: 0.380\n",
            "Epoch: 395/1000..  Train Loss: 1.305..  Train_Acc: 0.552..  Val Loss: 1.498..  Val_Acc: 0.354\n",
            "Epoch: 396/1000..  Train Loss: 1.303..  Train_Acc: 0.551..  Val Loss: 1.472..  Val_Acc: 0.384\n",
            "Epoch: 397/1000..  Train Loss: 1.307..  Train_Acc: 0.545..  Val Loss: 1.468..  Val_Acc: 0.380\n",
            "Epoch: 398/1000..  Train Loss: 1.304..  Train_Acc: 0.552..  Val Loss: 1.489..  Val_Acc: 0.369\n",
            "Epoch: 399/1000..  Train Loss: 1.306..  Train_Acc: 0.545..  Val Loss: 1.469..  Val_Acc: 0.377\n",
            "Epoch: 400/1000..  Train Loss: 1.312..  Train_Acc: 0.544..  Val Loss: 1.477..  Val_Acc: 0.373\n",
            "Epoch: 401/1000..  Train Loss: 1.306..  Train_Acc: 0.543..  Val Loss: 1.471..  Val_Acc: 0.380\n",
            "Epoch: 402/1000..  Train Loss: 1.300..  Train_Acc: 0.554..  Val Loss: 1.481..  Val_Acc: 0.370\n",
            "Epoch: 403/1000..  Train Loss: 1.303..  Train_Acc: 0.554..  Val Loss: 1.485..  Val_Acc: 0.365\n",
            "Epoch: 404/1000..  Train Loss: 1.299..  Train_Acc: 0.555..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 405/1000..  Train Loss: 1.299..  Train_Acc: 0.553..  Val Loss: 1.467..  Val_Acc: 0.372\n",
            "Epoch: 406/1000..  Train Loss: 1.298..  Train_Acc: 0.555..  Val Loss: 1.489..  Val_Acc: 0.363\n",
            "Epoch: 407/1000..  Train Loss: 1.302..  Train_Acc: 0.552..  Val Loss: 1.480..  Val_Acc: 0.370\n",
            "Epoch: 408/1000..  Train Loss: 1.303..  Train_Acc: 0.553..  Val Loss: 1.463..  Val_Acc: 0.380\n",
            "Epoch: 409/1000..  Train Loss: 1.307..  Train_Acc: 0.546..  Val Loss: 1.474..  Val_Acc: 0.366\n",
            "Epoch: 410/1000..  Train Loss: 1.298..  Train_Acc: 0.556..  Val Loss: 1.491..  Val_Acc: 0.357\n",
            "Epoch: 411/1000..  Train Loss: 1.297..  Train_Acc: 0.558..  Val Loss: 1.498..  Val_Acc: 0.351\n",
            "Epoch: 412/1000..  Train Loss: 1.293..  Train_Acc: 0.557..  Val Loss: 1.503..  Val_Acc: 0.350\n",
            "Epoch: 413/1000..  Train Loss: 1.299..  Train_Acc: 0.557..  Val Loss: 1.495..  Val_Acc: 0.358\n",
            "Epoch: 414/1000..  Train Loss: 1.296..  Train_Acc: 0.556..  Val Loss: 1.503..  Val_Acc: 0.348\n",
            "Epoch: 415/1000..  Train Loss: 1.299..  Train_Acc: 0.561..  Val Loss: 1.477..  Val_Acc: 0.374\n",
            "Epoch: 416/1000..  Train Loss: 1.297..  Train_Acc: 0.557..  Val Loss: 1.485..  Val_Acc: 0.364\n",
            "Epoch: 417/1000..  Train Loss: 1.302..  Train_Acc: 0.549..  Val Loss: 1.492..  Val_Acc: 0.360\n",
            "Epoch: 418/1000..  Train Loss: 1.293..  Train_Acc: 0.561..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 419/1000..  Train Loss: 1.293..  Train_Acc: 0.562..  Val Loss: 1.493..  Val_Acc: 0.362\n",
            "Epoch: 420/1000..  Train Loss: 1.290..  Train_Acc: 0.561..  Val Loss: 1.463..  Val_Acc: 0.385\n",
            "Epoch: 421/1000..  Train Loss: 1.295..  Train_Acc: 0.562..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 422/1000..  Train Loss: 1.291..  Train_Acc: 0.563..  Val Loss: 1.475..  Val_Acc: 0.370\n",
            "Epoch: 423/1000..  Train Loss: 1.292..  Train_Acc: 0.563..  Val Loss: 1.479..  Val_Acc: 0.366\n",
            "Epoch: 424/1000..  Train Loss: 1.287..  Train_Acc: 0.569..  Val Loss: 1.478..  Val_Acc: 0.371\n",
            "Epoch: 425/1000..  Train Loss: 1.297..  Train_Acc: 0.553..  Val Loss: 1.478..  Val_Acc: 0.366\n",
            "Epoch: 426/1000..  Train Loss: 1.286..  Train_Acc: 0.564..  Val Loss: 1.485..  Val_Acc: 0.366\n",
            "Epoch: 427/1000..  Train Loss: 1.295..  Train_Acc: 0.560..  Val Loss: 1.472..  Val_Acc: 0.381\n",
            "Epoch: 428/1000..  Train Loss: 1.297..  Train_Acc: 0.556..  Val Loss: 1.449..  Val_Acc: 0.388\n",
            "Epoch: 429/1000..  Train Loss: 1.304..  Train_Acc: 0.552..  Val Loss: 1.479..  Val_Acc: 0.367\n",
            "Epoch: 430/1000..  Train Loss: 1.290..  Train_Acc: 0.559..  Val Loss: 1.474..  Val_Acc: 0.372\n",
            "Epoch: 431/1000..  Train Loss: 1.291..  Train_Acc: 0.561..  Val Loss: 1.480..  Val_Acc: 0.367\n",
            "Epoch: 432/1000..  Train Loss: 1.290..  Train_Acc: 0.568..  Val Loss: 1.477..  Val_Acc: 0.373\n",
            "Epoch: 433/1000..  Train Loss: 1.294..  Train_Acc: 0.561..  Val Loss: 1.474..  Val_Acc: 0.376\n",
            "Epoch: 434/1000..  Train Loss: 1.289..  Train_Acc: 0.560..  Val Loss: 1.474..  Val_Acc: 0.375\n",
            "Epoch: 435/1000..  Train Loss: 1.298..  Train_Acc: 0.553..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 436/1000..  Train Loss: 1.284..  Train_Acc: 0.572..  Val Loss: 1.475..  Val_Acc: 0.371\n",
            "Epoch: 437/1000..  Train Loss: 1.289..  Train_Acc: 0.564..  Val Loss: 1.477..  Val_Acc: 0.362\n",
            "Epoch: 438/1000..  Train Loss: 1.290..  Train_Acc: 0.565..  Val Loss: 1.487..  Val_Acc: 0.365\n",
            "Epoch: 439/1000..  Train Loss: 1.285..  Train_Acc: 0.568..  Val Loss: 1.509..  Val_Acc: 0.344\n",
            "Epoch: 440/1000..  Train Loss: 1.289..  Train_Acc: 0.568..  Val Loss: 1.486..  Val_Acc: 0.367\n",
            "Epoch: 441/1000..  Train Loss: 1.288..  Train_Acc: 0.564..  Val Loss: 1.497..  Val_Acc: 0.348\n",
            "Epoch: 442/1000..  Train Loss: 1.300..  Train_Acc: 0.551..  Val Loss: 1.487..  Val_Acc: 0.368\n",
            "Epoch: 443/1000..  Train Loss: 1.298..  Train_Acc: 0.553..  Val Loss: 1.486..  Val_Acc: 0.363\n",
            "Epoch: 444/1000..  Train Loss: 1.283..  Train_Acc: 0.574..  Val Loss: 1.477..  Val_Acc: 0.372\n",
            "Epoch: 445/1000..  Train Loss: 1.285..  Train_Acc: 0.567..  Val Loss: 1.468..  Val_Acc: 0.368\n",
            "Epoch: 446/1000..  Train Loss: 1.285..  Train_Acc: 0.568..  Val Loss: 1.488..  Val_Acc: 0.355\n",
            "Epoch: 447/1000..  Train Loss: 1.281..  Train_Acc: 0.569..  Val Loss: 1.491..  Val_Acc: 0.355\n",
            "Epoch: 448/1000..  Train Loss: 1.280..  Train_Acc: 0.575..  Val Loss: 1.486..  Val_Acc: 0.364\n",
            "Epoch: 449/1000..  Train Loss: 1.281..  Train_Acc: 0.575..  Val Loss: 1.500..  Val_Acc: 0.350\n",
            "Epoch: 450/1000..  Train Loss: 1.288..  Train_Acc: 0.568..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 451/1000..  Train Loss: 1.290..  Train_Acc: 0.557..  Val Loss: 1.494..  Val_Acc: 0.350\n",
            "Epoch: 452/1000..  Train Loss: 1.281..  Train_Acc: 0.571..  Val Loss: 1.488..  Val_Acc: 0.364\n",
            "Epoch: 453/1000..  Train Loss: 1.278..  Train_Acc: 0.577..  Val Loss: 1.495..  Val_Acc: 0.354\n",
            "Epoch: 454/1000..  Train Loss: 1.280..  Train_Acc: 0.575..  Val Loss: 1.496..  Val_Acc: 0.349\n",
            "Epoch: 455/1000..  Train Loss: 1.278..  Train_Acc: 0.570..  Val Loss: 1.496..  Val_Acc: 0.356\n",
            "Epoch: 456/1000..  Train Loss: 1.279..  Train_Acc: 0.573..  Val Loss: 1.497..  Val_Acc: 0.352\n",
            "Epoch: 457/1000..  Train Loss: 1.282..  Train_Acc: 0.575..  Val Loss: 1.493..  Val_Acc: 0.350\n",
            "Epoch: 458/1000..  Train Loss: 1.290..  Train_Acc: 0.564..  Val Loss: 1.501..  Val_Acc: 0.349\n",
            "Epoch: 459/1000..  Train Loss: 1.292..  Train_Acc: 0.563..  Val Loss: 1.478..  Val_Acc: 0.370\n",
            "Epoch: 460/1000..  Train Loss: 1.277..  Train_Acc: 0.575..  Val Loss: 1.478..  Val_Acc: 0.370\n",
            "Epoch: 461/1000..  Train Loss: 1.281..  Train_Acc: 0.571..  Val Loss: 1.480..  Val_Acc: 0.371\n",
            "Epoch: 462/1000..  Train Loss: 1.286..  Train_Acc: 0.570..  Val Loss: 1.492..  Val_Acc: 0.366\n",
            "Epoch: 463/1000..  Train Loss: 1.284..  Train_Acc: 0.569..  Val Loss: 1.483..  Val_Acc: 0.371\n",
            "Epoch: 464/1000..  Train Loss: 1.278..  Train_Acc: 0.574..  Val Loss: 1.491..  Val_Acc: 0.359\n",
            "Epoch: 465/1000..  Train Loss: 1.285..  Train_Acc: 0.568..  Val Loss: 1.488..  Val_Acc: 0.357\n",
            "Epoch: 466/1000..  Train Loss: 1.287..  Train_Acc: 0.567..  Val Loss: 1.485..  Val_Acc: 0.370\n",
            "Epoch: 467/1000..  Train Loss: 1.286..  Train_Acc: 0.568..  Val Loss: 1.480..  Val_Acc: 0.373\n",
            "Epoch: 468/1000..  Train Loss: 1.272..  Train_Acc: 0.588..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 469/1000..  Train Loss: 1.278..  Train_Acc: 0.571..  Val Loss: 1.482..  Val_Acc: 0.361\n",
            "Epoch: 470/1000..  Train Loss: 1.277..  Train_Acc: 0.574..  Val Loss: 1.468..  Val_Acc: 0.372\n",
            "Epoch: 471/1000..  Train Loss: 1.271..  Train_Acc: 0.579..  Val Loss: 1.487..  Val_Acc: 0.355\n",
            "Epoch: 472/1000..  Train Loss: 1.280..  Train_Acc: 0.574..  Val Loss: 1.483..  Val_Acc: 0.356\n",
            "Epoch: 473/1000..  Train Loss: 1.278..  Train_Acc: 0.574..  Val Loss: 1.461..  Val_Acc: 0.385\n",
            "Epoch: 474/1000..  Train Loss: 1.269..  Train_Acc: 0.583..  Val Loss: 1.479..  Val_Acc: 0.373\n",
            "Epoch: 475/1000..  Train Loss: 1.278..  Train_Acc: 0.571..  Val Loss: 1.482..  Val_Acc: 0.375\n",
            "Epoch: 476/1000..  Train Loss: 1.276..  Train_Acc: 0.578..  Val Loss: 1.474..  Val_Acc: 0.377\n",
            "Epoch: 477/1000..  Train Loss: 1.277..  Train_Acc: 0.575..  Val Loss: 1.479..  Val_Acc: 0.364\n",
            "Epoch: 478/1000..  Train Loss: 1.284..  Train_Acc: 0.569..  Val Loss: 1.477..  Val_Acc: 0.372\n",
            "Epoch: 479/1000..  Train Loss: 1.265..  Train_Acc: 0.590..  Val Loss: 1.473..  Val_Acc: 0.377\n",
            "Epoch: 480/1000..  Train Loss: 1.271..  Train_Acc: 0.581..  Val Loss: 1.485..  Val_Acc: 0.366\n",
            "Epoch: 481/1000..  Train Loss: 1.279..  Train_Acc: 0.577..  Val Loss: 1.468..  Val_Acc: 0.375\n",
            "Epoch: 482/1000..  Train Loss: 1.272..  Train_Acc: 0.580..  Val Loss: 1.469..  Val_Acc: 0.377\n",
            "Epoch: 483/1000..  Train Loss: 1.278..  Train_Acc: 0.575..  Val Loss: 1.484..  Val_Acc: 0.362\n",
            "Epoch: 484/1000..  Train Loss: 1.269..  Train_Acc: 0.583..  Val Loss: 1.470..  Val_Acc: 0.376\n",
            "Epoch: 485/1000..  Train Loss: 1.266..  Train_Acc: 0.587..  Val Loss: 1.488..  Val_Acc: 0.364\n",
            "Epoch: 486/1000..  Train Loss: 1.292..  Train_Acc: 0.562..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 487/1000..  Train Loss: 1.274..  Train_Acc: 0.583..  Val Loss: 1.496..  Val_Acc: 0.349\n",
            "Epoch: 488/1000..  Train Loss: 1.280..  Train_Acc: 0.572..  Val Loss: 1.479..  Val_Acc: 0.368\n",
            "Epoch: 489/1000..  Train Loss: 1.288..  Train_Acc: 0.562..  Val Loss: 1.488..  Val_Acc: 0.365\n",
            "Epoch: 490/1000..  Train Loss: 1.274..  Train_Acc: 0.584..  Val Loss: 1.480..  Val_Acc: 0.366\n",
            "Epoch: 491/1000..  Train Loss: 1.279..  Train_Acc: 0.570..  Val Loss: 1.500..  Val_Acc: 0.356\n",
            "Epoch: 492/1000..  Train Loss: 1.282..  Train_Acc: 0.573..  Val Loss: 1.493..  Val_Acc: 0.354\n",
            "Epoch: 493/1000..  Train Loss: 1.278..  Train_Acc: 0.575..  Val Loss: 1.480..  Val_Acc: 0.374\n",
            "Epoch: 494/1000..  Train Loss: 1.268..  Train_Acc: 0.584..  Val Loss: 1.491..  Val_Acc: 0.357\n",
            "Epoch: 495/1000..  Train Loss: 1.273..  Train_Acc: 0.580..  Val Loss: 1.491..  Val_Acc: 0.360\n",
            "Epoch: 496/1000..  Train Loss: 1.271..  Train_Acc: 0.581..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 497/1000..  Train Loss: 1.274..  Train_Acc: 0.585..  Val Loss: 1.478..  Val_Acc: 0.363\n",
            "Epoch: 498/1000..  Train Loss: 1.273..  Train_Acc: 0.578..  Val Loss: 1.482..  Val_Acc: 0.366\n",
            "Epoch: 499/1000..  Train Loss: 1.272..  Train_Acc: 0.581..  Val Loss: 1.474..  Val_Acc: 0.375\n",
            "Epoch: 500/1000..  Train Loss: 1.271..  Train_Acc: 0.577..  Val Loss: 1.472..  Val_Acc: 0.373\n",
            "Epoch: 501/1000..  Train Loss: 1.279..  Train_Acc: 0.574..  Val Loss: 1.480..  Val_Acc: 0.366\n",
            "Epoch: 502/1000..  Train Loss: 1.275..  Train_Acc: 0.574..  Val Loss: 1.467..  Val_Acc: 0.377\n",
            "Epoch: 503/1000..  Train Loss: 1.271..  Train_Acc: 0.585..  Val Loss: 1.465..  Val_Acc: 0.382\n",
            "Epoch: 504/1000..  Train Loss: 1.268..  Train_Acc: 0.585..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 505/1000..  Train Loss: 1.271..  Train_Acc: 0.584..  Val Loss: 1.477..  Val_Acc: 0.368\n",
            "Epoch: 506/1000..  Train Loss: 1.265..  Train_Acc: 0.583..  Val Loss: 1.475..  Val_Acc: 0.370\n",
            "Epoch: 507/1000..  Train Loss: 1.261..  Train_Acc: 0.586..  Val Loss: 1.482..  Val_Acc: 0.364\n",
            "Epoch: 508/1000..  Train Loss: 1.273..  Train_Acc: 0.579..  Val Loss: 1.477..  Val_Acc: 0.370\n",
            "Epoch: 509/1000..  Train Loss: 1.264..  Train_Acc: 0.591..  Val Loss: 1.471..  Val_Acc: 0.366\n",
            "Epoch: 510/1000..  Train Loss: 1.260..  Train_Acc: 0.597..  Val Loss: 1.486..  Val_Acc: 0.368\n",
            "Epoch: 511/1000..  Train Loss: 1.269..  Train_Acc: 0.584..  Val Loss: 1.476..  Val_Acc: 0.373\n",
            "Epoch: 512/1000..  Train Loss: 1.264..  Train_Acc: 0.591..  Val Loss: 1.475..  Val_Acc: 0.368\n",
            "Epoch: 513/1000..  Train Loss: 1.265..  Train_Acc: 0.586..  Val Loss: 1.466..  Val_Acc: 0.376\n",
            "Epoch: 514/1000..  Train Loss: 1.261..  Train_Acc: 0.597..  Val Loss: 1.474..  Val_Acc: 0.378\n",
            "Epoch: 515/1000..  Train Loss: 1.268..  Train_Acc: 0.585..  Val Loss: 1.479..  Val_Acc: 0.367\n",
            "Epoch: 516/1000..  Train Loss: 1.263..  Train_Acc: 0.592..  Val Loss: 1.487..  Val_Acc: 0.358\n",
            "Epoch: 517/1000..  Train Loss: 1.271..  Train_Acc: 0.582..  Val Loss: 1.487..  Val_Acc: 0.355\n",
            "Epoch: 518/1000..  Train Loss: 1.260..  Train_Acc: 0.593..  Val Loss: 1.480..  Val_Acc: 0.362\n",
            "Epoch: 519/1000..  Train Loss: 1.269..  Train_Acc: 0.582..  Val Loss: 1.473..  Val_Acc: 0.366\n",
            "Epoch: 520/1000..  Train Loss: 1.266..  Train_Acc: 0.585..  Val Loss: 1.492..  Val_Acc: 0.355\n",
            "Epoch: 521/1000..  Train Loss: 1.262..  Train_Acc: 0.590..  Val Loss: 1.503..  Val_Acc: 0.350\n",
            "Epoch: 522/1000..  Train Loss: 1.265..  Train_Acc: 0.590..  Val Loss: 1.489..  Val_Acc: 0.356\n",
            "Epoch: 523/1000..  Train Loss: 1.260..  Train_Acc: 0.590..  Val Loss: 1.491..  Val_Acc: 0.353\n",
            "Epoch: 524/1000..  Train Loss: 1.259..  Train_Acc: 0.591..  Val Loss: 1.494..  Val_Acc: 0.352\n",
            "Epoch: 525/1000..  Train Loss: 1.258..  Train_Acc: 0.595..  Val Loss: 1.493..  Val_Acc: 0.359\n",
            "Epoch: 526/1000..  Train Loss: 1.261..  Train_Acc: 0.589..  Val Loss: 1.504..  Val_Acc: 0.345\n",
            "Epoch: 527/1000..  Train Loss: 1.259..  Train_Acc: 0.588..  Val Loss: 1.491..  Val_Acc: 0.362\n",
            "Epoch: 528/1000..  Train Loss: 1.266..  Train_Acc: 0.587..  Val Loss: 1.474..  Val_Acc: 0.371\n",
            "Epoch: 529/1000..  Train Loss: 1.256..  Train_Acc: 0.599..  Val Loss: 1.484..  Val_Acc: 0.364\n",
            "Epoch: 530/1000..  Train Loss: 1.259..  Train_Acc: 0.595..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 531/1000..  Train Loss: 1.260..  Train_Acc: 0.596..  Val Loss: 1.477..  Val_Acc: 0.367\n",
            "Epoch: 532/1000..  Train Loss: 1.258..  Train_Acc: 0.595..  Val Loss: 1.489..  Val_Acc: 0.358\n",
            "Epoch: 533/1000..  Train Loss: 1.261..  Train_Acc: 0.592..  Val Loss: 1.509..  Val_Acc: 0.343\n",
            "Epoch: 534/1000..  Train Loss: 1.260..  Train_Acc: 0.591..  Val Loss: 1.499..  Val_Acc: 0.354\n",
            "Epoch: 535/1000..  Train Loss: 1.252..  Train_Acc: 0.602..  Val Loss: 1.492..  Val_Acc: 0.355\n",
            "Epoch: 536/1000..  Train Loss: 1.261..  Train_Acc: 0.591..  Val Loss: 1.496..  Val_Acc: 0.353\n",
            "Epoch: 537/1000..  Train Loss: 1.261..  Train_Acc: 0.595..  Val Loss: 1.497..  Val_Acc: 0.354\n",
            "Epoch: 538/1000..  Train Loss: 1.262..  Train_Acc: 0.595..  Val Loss: 1.478..  Val_Acc: 0.366\n",
            "Epoch: 539/1000..  Train Loss: 1.258..  Train_Acc: 0.596..  Val Loss: 1.490..  Val_Acc: 0.354\n",
            "Epoch: 540/1000..  Train Loss: 1.255..  Train_Acc: 0.592..  Val Loss: 1.492..  Val_Acc: 0.355\n",
            "Epoch: 541/1000..  Train Loss: 1.252..  Train_Acc: 0.602..  Val Loss: 1.482..  Val_Acc: 0.368\n",
            "Epoch: 542/1000..  Train Loss: 1.256..  Train_Acc: 0.597..  Val Loss: 1.477..  Val_Acc: 0.367\n",
            "Epoch: 543/1000..  Train Loss: 1.255..  Train_Acc: 0.599..  Val Loss: 1.514..  Val_Acc: 0.338\n",
            "Epoch: 544/1000..  Train Loss: 1.253..  Train_Acc: 0.601..  Val Loss: 1.487..  Val_Acc: 0.360\n",
            "Epoch: 545/1000..  Train Loss: 1.259..  Train_Acc: 0.598..  Val Loss: 1.499..  Val_Acc: 0.355\n",
            "Epoch: 546/1000..  Train Loss: 1.262..  Train_Acc: 0.591..  Val Loss: 1.492..  Val_Acc: 0.352\n",
            "Epoch: 547/1000..  Train Loss: 1.254..  Train_Acc: 0.594..  Val Loss: 1.479..  Val_Acc: 0.365\n",
            "Epoch: 548/1000..  Train Loss: 1.252..  Train_Acc: 0.595..  Val Loss: 1.479..  Val_Acc: 0.367\n",
            "Epoch: 549/1000..  Train Loss: 1.253..  Train_Acc: 0.597..  Val Loss: 1.490..  Val_Acc: 0.357\n",
            "Epoch: 550/1000..  Train Loss: 1.263..  Train_Acc: 0.587..  Val Loss: 1.475..  Val_Acc: 0.373\n",
            "Epoch: 551/1000..  Train Loss: 1.254..  Train_Acc: 0.600..  Val Loss: 1.489..  Val_Acc: 0.365\n",
            "Epoch: 552/1000..  Train Loss: 1.248..  Train_Acc: 0.608..  Val Loss: 1.488..  Val_Acc: 0.373\n",
            "Epoch: 553/1000..  Train Loss: 1.265..  Train_Acc: 0.584..  Val Loss: 1.469..  Val_Acc: 0.375\n",
            "Epoch: 554/1000..  Train Loss: 1.265..  Train_Acc: 0.586..  Val Loss: 1.500..  Val_Acc: 0.342\n",
            "Epoch: 555/1000..  Train Loss: 1.260..  Train_Acc: 0.590..  Val Loss: 1.493..  Val_Acc: 0.362\n",
            "Epoch: 556/1000..  Train Loss: 1.246..  Train_Acc: 0.605..  Val Loss: 1.479..  Val_Acc: 0.373\n",
            "Epoch: 557/1000..  Train Loss: 1.254..  Train_Acc: 0.598..  Val Loss: 1.494..  Val_Acc: 0.362\n",
            "Epoch: 558/1000..  Train Loss: 1.250..  Train_Acc: 0.606..  Val Loss: 1.481..  Val_Acc: 0.366\n",
            "Epoch: 559/1000..  Train Loss: 1.241..  Train_Acc: 0.612..  Val Loss: 1.511..  Val_Acc: 0.344\n",
            "Epoch: 560/1000..  Train Loss: 1.248..  Train_Acc: 0.603..  Val Loss: 1.506..  Val_Acc: 0.345\n",
            "Epoch: 561/1000..  Train Loss: 1.247..  Train_Acc: 0.606..  Val Loss: 1.510..  Val_Acc: 0.347\n",
            "Epoch: 562/1000..  Train Loss: 1.251..  Train_Acc: 0.595..  Val Loss: 1.497..  Val_Acc: 0.353\n",
            "Epoch: 563/1000..  Train Loss: 1.256..  Train_Acc: 0.594..  Val Loss: 1.506..  Val_Acc: 0.348\n",
            "Epoch: 564/1000..  Train Loss: 1.247..  Train_Acc: 0.608..  Val Loss: 1.504..  Val_Acc: 0.345\n",
            "Epoch: 565/1000..  Train Loss: 1.254..  Train_Acc: 0.600..  Val Loss: 1.511..  Val_Acc: 0.342\n",
            "Epoch: 566/1000..  Train Loss: 1.256..  Train_Acc: 0.597..  Val Loss: 1.496..  Val_Acc: 0.354\n",
            "Epoch: 567/1000..  Train Loss: 1.249..  Train_Acc: 0.599..  Val Loss: 1.486..  Val_Acc: 0.359\n",
            "Epoch: 568/1000..  Train Loss: 1.250..  Train_Acc: 0.600..  Val Loss: 1.491..  Val_Acc: 0.359\n",
            "Epoch: 569/1000..  Train Loss: 1.252..  Train_Acc: 0.602..  Val Loss: 1.489..  Val_Acc: 0.354\n",
            "Epoch: 570/1000..  Train Loss: 1.252..  Train_Acc: 0.600..  Val Loss: 1.493..  Val_Acc: 0.352\n",
            "Epoch: 571/1000..  Train Loss: 1.247..  Train_Acc: 0.604..  Val Loss: 1.478..  Val_Acc: 0.372\n",
            "Epoch: 572/1000..  Train Loss: 1.257..  Train_Acc: 0.598..  Val Loss: 1.474..  Val_Acc: 0.373\n",
            "Epoch: 573/1000..  Train Loss: 1.249..  Train_Acc: 0.609..  Val Loss: 1.464..  Val_Acc: 0.377\n",
            "Epoch: 574/1000..  Train Loss: 1.242..  Train_Acc: 0.608..  Val Loss: 1.485..  Val_Acc: 0.363\n",
            "Epoch: 575/1000..  Train Loss: 1.248..  Train_Acc: 0.603..  Val Loss: 1.497..  Val_Acc: 0.352\n",
            "Epoch: 576/1000..  Train Loss: 1.250..  Train_Acc: 0.601..  Val Loss: 1.488..  Val_Acc: 0.360\n",
            "Epoch: 577/1000..  Train Loss: 1.250..  Train_Acc: 0.602..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 578/1000..  Train Loss: 1.246..  Train_Acc: 0.606..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 579/1000..  Train Loss: 1.242..  Train_Acc: 0.608..  Val Loss: 1.479..  Val_Acc: 0.368\n",
            "Epoch: 580/1000..  Train Loss: 1.257..  Train_Acc: 0.593..  Val Loss: 1.477..  Val_Acc: 0.367\n",
            "Epoch: 581/1000..  Train Loss: 1.244..  Train_Acc: 0.606..  Val Loss: 1.470..  Val_Acc: 0.374\n",
            "Epoch: 582/1000..  Train Loss: 1.251..  Train_Acc: 0.602..  Val Loss: 1.464..  Val_Acc: 0.376\n",
            "Epoch: 583/1000..  Train Loss: 1.244..  Train_Acc: 0.610..  Val Loss: 1.481..  Val_Acc: 0.367\n",
            "Epoch: 584/1000..  Train Loss: 1.244..  Train_Acc: 0.609..  Val Loss: 1.499..  Val_Acc: 0.359\n",
            "Epoch: 585/1000..  Train Loss: 1.247..  Train_Acc: 0.602..  Val Loss: 1.493..  Val_Acc: 0.358\n",
            "Epoch: 586/1000..  Train Loss: 1.251..  Train_Acc: 0.601..  Val Loss: 1.486..  Val_Acc: 0.366\n",
            "Epoch: 587/1000..  Train Loss: 1.247..  Train_Acc: 0.603..  Val Loss: 1.486..  Val_Acc: 0.364\n",
            "Epoch: 588/1000..  Train Loss: 1.249..  Train_Acc: 0.604..  Val Loss: 1.494..  Val_Acc: 0.362\n",
            "Epoch: 589/1000..  Train Loss: 1.248..  Train_Acc: 0.601..  Val Loss: 1.485..  Val_Acc: 0.363\n",
            "Epoch: 590/1000..  Train Loss: 1.242..  Train_Acc: 0.611..  Val Loss: 1.489..  Val_Acc: 0.359\n",
            "Epoch: 591/1000..  Train Loss: 1.238..  Train_Acc: 0.614..  Val Loss: 1.491..  Val_Acc: 0.356\n",
            "Epoch: 592/1000..  Train Loss: 1.238..  Train_Acc: 0.613..  Val Loss: 1.490..  Val_Acc: 0.363\n",
            "Epoch: 593/1000..  Train Loss: 1.239..  Train_Acc: 0.618..  Val Loss: 1.495..  Val_Acc: 0.366\n",
            "Epoch: 594/1000..  Train Loss: 1.240..  Train_Acc: 0.611..  Val Loss: 1.475..  Val_Acc: 0.375\n",
            "Epoch: 595/1000..  Train Loss: 1.243..  Train_Acc: 0.610..  Val Loss: 1.477..  Val_Acc: 0.373\n",
            "Epoch: 596/1000..  Train Loss: 1.243..  Train_Acc: 0.612..  Val Loss: 1.470..  Val_Acc: 0.375\n",
            "Epoch: 597/1000..  Train Loss: 1.250..  Train_Acc: 0.601..  Val Loss: 1.492..  Val_Acc: 0.362\n",
            "Epoch: 598/1000..  Train Loss: 1.243..  Train_Acc: 0.606..  Val Loss: 1.478..  Val_Acc: 0.369\n",
            "Epoch: 599/1000..  Train Loss: 1.239..  Train_Acc: 0.612..  Val Loss: 1.493..  Val_Acc: 0.361\n",
            "Epoch: 600/1000..  Train Loss: 1.247..  Train_Acc: 0.603..  Val Loss: 1.476..  Val_Acc: 0.373\n",
            "Epoch: 601/1000..  Train Loss: 1.242..  Train_Acc: 0.610..  Val Loss: 1.499..  Val_Acc: 0.357\n",
            "Epoch: 602/1000..  Train Loss: 1.240..  Train_Acc: 0.611..  Val Loss: 1.473..  Val_Acc: 0.374\n",
            "Epoch: 603/1000..  Train Loss: 1.239..  Train_Acc: 0.610..  Val Loss: 1.489..  Val_Acc: 0.366\n",
            "Epoch: 604/1000..  Train Loss: 1.238..  Train_Acc: 0.614..  Val Loss: 1.469..  Val_Acc: 0.387\n",
            "Epoch: 605/1000..  Train Loss: 1.236..  Train_Acc: 0.616..  Val Loss: 1.475..  Val_Acc: 0.373\n",
            "Epoch: 606/1000..  Train Loss: 1.239..  Train_Acc: 0.616..  Val Loss: 1.476..  Val_Acc: 0.374\n",
            "Epoch: 607/1000..  Train Loss: 1.235..  Train_Acc: 0.615..  Val Loss: 1.495..  Val_Acc: 0.359\n",
            "Epoch: 608/1000..  Train Loss: 1.238..  Train_Acc: 0.609..  Val Loss: 1.479..  Val_Acc: 0.370\n",
            "Epoch: 609/1000..  Train Loss: 1.244..  Train_Acc: 0.613..  Val Loss: 1.475..  Val_Acc: 0.372\n",
            "Epoch: 610/1000..  Train Loss: 1.241..  Train_Acc: 0.609..  Val Loss: 1.490..  Val_Acc: 0.362\n",
            "Epoch: 611/1000..  Train Loss: 1.240..  Train_Acc: 0.615..  Val Loss: 1.488..  Val_Acc: 0.370\n",
            "Epoch: 612/1000..  Train Loss: 1.239..  Train_Acc: 0.614..  Val Loss: 1.480..  Val_Acc: 0.368\n",
            "Epoch: 613/1000..  Train Loss: 1.248..  Train_Acc: 0.603..  Val Loss: 1.489..  Val_Acc: 0.362\n",
            "Epoch: 614/1000..  Train Loss: 1.244..  Train_Acc: 0.611..  Val Loss: 1.483..  Val_Acc: 0.368\n",
            "Epoch: 615/1000..  Train Loss: 1.241..  Train_Acc: 0.612..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 616/1000..  Train Loss: 1.236..  Train_Acc: 0.615..  Val Loss: 1.485..  Val_Acc: 0.368\n",
            "Epoch: 617/1000..  Train Loss: 1.244..  Train_Acc: 0.607..  Val Loss: 1.483..  Val_Acc: 0.366\n",
            "Epoch: 618/1000..  Train Loss: 1.247..  Train_Acc: 0.602..  Val Loss: 1.487..  Val_Acc: 0.363\n",
            "Epoch: 619/1000..  Train Loss: 1.244..  Train_Acc: 0.611..  Val Loss: 1.493..  Val_Acc: 0.359\n",
            "Epoch: 620/1000..  Train Loss: 1.242..  Train_Acc: 0.615..  Val Loss: 1.483..  Val_Acc: 0.366\n",
            "Epoch: 621/1000..  Train Loss: 1.244..  Train_Acc: 0.609..  Val Loss: 1.498..  Val_Acc: 0.357\n",
            "Epoch: 622/1000..  Train Loss: 1.248..  Train_Acc: 0.604..  Val Loss: 1.500..  Val_Acc: 0.357\n",
            "Epoch: 623/1000..  Train Loss: 1.239..  Train_Acc: 0.617..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 624/1000..  Train Loss: 1.239..  Train_Acc: 0.619..  Val Loss: 1.497..  Val_Acc: 0.358\n",
            "Epoch: 625/1000..  Train Loss: 1.239..  Train_Acc: 0.616..  Val Loss: 1.496..  Val_Acc: 0.359\n",
            "Epoch: 626/1000..  Train Loss: 1.244..  Train_Acc: 0.604..  Val Loss: 1.485..  Val_Acc: 0.370\n",
            "Epoch: 627/1000..  Train Loss: 1.246..  Train_Acc: 0.605..  Val Loss: 1.486..  Val_Acc: 0.363\n",
            "Epoch: 628/1000..  Train Loss: 1.234..  Train_Acc: 0.616..  Val Loss: 1.497..  Val_Acc: 0.355\n",
            "Epoch: 629/1000..  Train Loss: 1.232..  Train_Acc: 0.618..  Val Loss: 1.501..  Val_Acc: 0.353\n",
            "Epoch: 630/1000..  Train Loss: 1.236..  Train_Acc: 0.618..  Val Loss: 1.499..  Val_Acc: 0.355\n",
            "Epoch: 631/1000..  Train Loss: 1.237..  Train_Acc: 0.618..  Val Loss: 1.483..  Val_Acc: 0.374\n",
            "Epoch: 632/1000..  Train Loss: 1.240..  Train_Acc: 0.610..  Val Loss: 1.492..  Val_Acc: 0.358\n",
            "Epoch: 633/1000..  Train Loss: 1.241..  Train_Acc: 0.613..  Val Loss: 1.501..  Val_Acc: 0.350\n",
            "Epoch: 634/1000..  Train Loss: 1.237..  Train_Acc: 0.617..  Val Loss: 1.493..  Val_Acc: 0.364\n",
            "Epoch: 635/1000..  Train Loss: 1.241..  Train_Acc: 0.609..  Val Loss: 1.503..  Val_Acc: 0.358\n",
            "Epoch: 636/1000..  Train Loss: 1.239..  Train_Acc: 0.612..  Val Loss: 1.498..  Val_Acc: 0.366\n",
            "Epoch: 637/1000..  Train Loss: 1.245..  Train_Acc: 0.609..  Val Loss: 1.495..  Val_Acc: 0.360\n",
            "Epoch: 638/1000..  Train Loss: 1.238..  Train_Acc: 0.616..  Val Loss: 1.503..  Val_Acc: 0.351\n",
            "Epoch: 639/1000..  Train Loss: 1.236..  Train_Acc: 0.616..  Val Loss: 1.489..  Val_Acc: 0.364\n",
            "Epoch: 640/1000..  Train Loss: 1.246..  Train_Acc: 0.607..  Val Loss: 1.497..  Val_Acc: 0.353\n",
            "Epoch: 641/1000..  Train Loss: 1.232..  Train_Acc: 0.623..  Val Loss: 1.505..  Val_Acc: 0.348\n",
            "Epoch: 642/1000..  Train Loss: 1.233..  Train_Acc: 0.621..  Val Loss: 1.485..  Val_Acc: 0.366\n",
            "Epoch: 643/1000..  Train Loss: 1.237..  Train_Acc: 0.615..  Val Loss: 1.488..  Val_Acc: 0.360\n",
            "Epoch: 644/1000..  Train Loss: 1.242..  Train_Acc: 0.610..  Val Loss: 1.478..  Val_Acc: 0.368\n",
            "Epoch: 645/1000..  Train Loss: 1.230..  Train_Acc: 0.624..  Val Loss: 1.481..  Val_Acc: 0.364\n",
            "Epoch: 646/1000..  Train Loss: 1.227..  Train_Acc: 0.621..  Val Loss: 1.484..  Val_Acc: 0.362\n",
            "Epoch: 647/1000..  Train Loss: 1.239..  Train_Acc: 0.612..  Val Loss: 1.473..  Val_Acc: 0.370\n",
            "Epoch: 648/1000..  Train Loss: 1.233..  Train_Acc: 0.622..  Val Loss: 1.478..  Val_Acc: 0.367\n",
            "Epoch: 649/1000..  Train Loss: 1.236..  Train_Acc: 0.617..  Val Loss: 1.490..  Val_Acc: 0.359\n",
            "Epoch: 650/1000..  Train Loss: 1.237..  Train_Acc: 0.614..  Val Loss: 1.493..  Val_Acc: 0.356\n",
            "Epoch: 651/1000..  Train Loss: 1.233..  Train_Acc: 0.615..  Val Loss: 1.482..  Val_Acc: 0.368\n",
            "Epoch: 652/1000..  Train Loss: 1.242..  Train_Acc: 0.607..  Val Loss: 1.492..  Val_Acc: 0.361\n",
            "Epoch: 653/1000..  Train Loss: 1.235..  Train_Acc: 0.619..  Val Loss: 1.481..  Val_Acc: 0.366\n",
            "Epoch: 654/1000..  Train Loss: 1.227..  Train_Acc: 0.625..  Val Loss: 1.476..  Val_Acc: 0.373\n",
            "Epoch: 655/1000..  Train Loss: 1.226..  Train_Acc: 0.628..  Val Loss: 1.482..  Val_Acc: 0.363\n",
            "Epoch: 656/1000..  Train Loss: 1.236..  Train_Acc: 0.613..  Val Loss: 1.503..  Val_Acc: 0.348\n",
            "Epoch: 657/1000..  Train Loss: 1.234..  Train_Acc: 0.617..  Val Loss: 1.501..  Val_Acc: 0.352\n",
            "Epoch: 658/1000..  Train Loss: 1.232..  Train_Acc: 0.623..  Val Loss: 1.492..  Val_Acc: 0.363\n",
            "Epoch: 659/1000..  Train Loss: 1.240..  Train_Acc: 0.609..  Val Loss: 1.487..  Val_Acc: 0.365\n",
            "Epoch: 660/1000..  Train Loss: 1.227..  Train_Acc: 0.623..  Val Loss: 1.494..  Val_Acc: 0.348\n",
            "Epoch: 661/1000..  Train Loss: 1.226..  Train_Acc: 0.623..  Val Loss: 1.491..  Val_Acc: 0.356\n",
            "Epoch: 662/1000..  Train Loss: 1.232..  Train_Acc: 0.620..  Val Loss: 1.483..  Val_Acc: 0.362\n",
            "Epoch: 663/1000..  Train Loss: 1.234..  Train_Acc: 0.617..  Val Loss: 1.511..  Val_Acc: 0.344\n",
            "Epoch: 664/1000..  Train Loss: 1.227..  Train_Acc: 0.625..  Val Loss: 1.506..  Val_Acc: 0.348\n",
            "Epoch: 665/1000..  Train Loss: 1.228..  Train_Acc: 0.617..  Val Loss: 1.507..  Val_Acc: 0.346\n",
            "Epoch: 666/1000..  Train Loss: 1.233..  Train_Acc: 0.615..  Val Loss: 1.504..  Val_Acc: 0.352\n",
            "Epoch: 667/1000..  Train Loss: 1.232..  Train_Acc: 0.615..  Val Loss: 1.498..  Val_Acc: 0.355\n",
            "Epoch: 668/1000..  Train Loss: 1.224..  Train_Acc: 0.628..  Val Loss: 1.495..  Val_Acc: 0.355\n",
            "Epoch: 669/1000..  Train Loss: 1.234..  Train_Acc: 0.614..  Val Loss: 1.502..  Val_Acc: 0.345\n",
            "Epoch: 670/1000..  Train Loss: 1.231..  Train_Acc: 0.617..  Val Loss: 1.499..  Val_Acc: 0.345\n",
            "Epoch: 671/1000..  Train Loss: 1.227..  Train_Acc: 0.626..  Val Loss: 1.487..  Val_Acc: 0.354\n",
            "Epoch: 672/1000..  Train Loss: 1.230..  Train_Acc: 0.623..  Val Loss: 1.506..  Val_Acc: 0.344\n",
            "Epoch: 673/1000..  Train Loss: 1.225..  Train_Acc: 0.626..  Val Loss: 1.491..  Val_Acc: 0.355\n",
            "Epoch: 674/1000..  Train Loss: 1.229..  Train_Acc: 0.619..  Val Loss: 1.500..  Val_Acc: 0.355\n",
            "Epoch: 675/1000..  Train Loss: 1.222..  Train_Acc: 0.632..  Val Loss: 1.507..  Val_Acc: 0.345\n",
            "Epoch: 676/1000..  Train Loss: 1.234..  Train_Acc: 0.619..  Val Loss: 1.500..  Val_Acc: 0.348\n",
            "Epoch: 677/1000..  Train Loss: 1.231..  Train_Acc: 0.624..  Val Loss: 1.486..  Val_Acc: 0.357\n",
            "Epoch: 678/1000..  Train Loss: 1.225..  Train_Acc: 0.624..  Val Loss: 1.486..  Val_Acc: 0.355\n",
            "Epoch: 679/1000..  Train Loss: 1.224..  Train_Acc: 0.632..  Val Loss: 1.492..  Val_Acc: 0.359\n",
            "Epoch: 680/1000..  Train Loss: 1.229..  Train_Acc: 0.625..  Val Loss: 1.493..  Val_Acc: 0.355\n",
            "Epoch: 681/1000..  Train Loss: 1.222..  Train_Acc: 0.635..  Val Loss: 1.487..  Val_Acc: 0.358\n",
            "Epoch: 682/1000..  Train Loss: 1.228..  Train_Acc: 0.617..  Val Loss: 1.488..  Val_Acc: 0.353\n",
            "Epoch: 683/1000..  Train Loss: 1.219..  Train_Acc: 0.632..  Val Loss: 1.496..  Val_Acc: 0.353\n",
            "Epoch: 684/1000..  Train Loss: 1.230..  Train_Acc: 0.619..  Val Loss: 1.492..  Val_Acc: 0.350\n",
            "Epoch: 685/1000..  Train Loss: 1.229..  Train_Acc: 0.624..  Val Loss: 1.489..  Val_Acc: 0.352\n",
            "Epoch: 686/1000..  Train Loss: 1.226..  Train_Acc: 0.621..  Val Loss: 1.480..  Val_Acc: 0.355\n",
            "Epoch: 687/1000..  Train Loss: 1.229..  Train_Acc: 0.625..  Val Loss: 1.486..  Val_Acc: 0.363\n",
            "Epoch: 688/1000..  Train Loss: 1.222..  Train_Acc: 0.629..  Val Loss: 1.486..  Val_Acc: 0.366\n",
            "Epoch: 689/1000..  Train Loss: 1.228..  Train_Acc: 0.624..  Val Loss: 1.492..  Val_Acc: 0.350\n",
            "Epoch: 690/1000..  Train Loss: 1.224..  Train_Acc: 0.630..  Val Loss: 1.479..  Val_Acc: 0.362\n",
            "Epoch: 691/1000..  Train Loss: 1.225..  Train_Acc: 0.626..  Val Loss: 1.477..  Val_Acc: 0.359\n",
            "Epoch: 692/1000..  Train Loss: 1.222..  Train_Acc: 0.629..  Val Loss: 1.474..  Val_Acc: 0.367\n",
            "Epoch: 693/1000..  Train Loss: 1.226..  Train_Acc: 0.628..  Val Loss: 1.478..  Val_Acc: 0.364\n",
            "Epoch: 694/1000..  Train Loss: 1.220..  Train_Acc: 0.632..  Val Loss: 1.475..  Val_Acc: 0.368\n",
            "Epoch: 695/1000..  Train Loss: 1.221..  Train_Acc: 0.631..  Val Loss: 1.470..  Val_Acc: 0.377\n",
            "Epoch: 696/1000..  Train Loss: 1.226..  Train_Acc: 0.618..  Val Loss: 1.500..  Val_Acc: 0.347\n",
            "Epoch: 697/1000..  Train Loss: 1.219..  Train_Acc: 0.633..  Val Loss: 1.490..  Val_Acc: 0.360\n",
            "Epoch: 698/1000..  Train Loss: 1.220..  Train_Acc: 0.633..  Val Loss: 1.470..  Val_Acc: 0.374\n",
            "Epoch: 699/1000..  Train Loss: 1.216..  Train_Acc: 0.636..  Val Loss: 1.499..  Val_Acc: 0.345\n",
            "Epoch: 700/1000..  Train Loss: 1.224..  Train_Acc: 0.629..  Val Loss: 1.484..  Val_Acc: 0.369\n",
            "Epoch: 701/1000..  Train Loss: 1.222..  Train_Acc: 0.630..  Val Loss: 1.469..  Val_Acc: 0.377\n",
            "Epoch: 702/1000..  Train Loss: 1.219..  Train_Acc: 0.634..  Val Loss: 1.491..  Val_Acc: 0.362\n",
            "Epoch: 703/1000..  Train Loss: 1.223..  Train_Acc: 0.632..  Val Loss: 1.496..  Val_Acc: 0.356\n",
            "Epoch: 704/1000..  Train Loss: 1.222..  Train_Acc: 0.627..  Val Loss: 1.487..  Val_Acc: 0.361\n",
            "Epoch: 705/1000..  Train Loss: 1.215..  Train_Acc: 0.639..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 706/1000..  Train Loss: 1.218..  Train_Acc: 0.635..  Val Loss: 1.483..  Val_Acc: 0.368\n",
            "Epoch: 707/1000..  Train Loss: 1.223..  Train_Acc: 0.628..  Val Loss: 1.483..  Val_Acc: 0.364\n",
            "Epoch: 708/1000..  Train Loss: 1.219..  Train_Acc: 0.634..  Val Loss: 1.490..  Val_Acc: 0.355\n",
            "Epoch: 709/1000..  Train Loss: 1.218..  Train_Acc: 0.636..  Val Loss: 1.491..  Val_Acc: 0.357\n",
            "Epoch: 710/1000..  Train Loss: 1.214..  Train_Acc: 0.638..  Val Loss: 1.492..  Val_Acc: 0.350\n",
            "Epoch: 711/1000..  Train Loss: 1.224..  Train_Acc: 0.628..  Val Loss: 1.491..  Val_Acc: 0.359\n",
            "Epoch: 712/1000..  Train Loss: 1.220..  Train_Acc: 0.628..  Val Loss: 1.488..  Val_Acc: 0.363\n",
            "Epoch: 713/1000..  Train Loss: 1.218..  Train_Acc: 0.635..  Val Loss: 1.495..  Val_Acc: 0.355\n",
            "Epoch: 714/1000..  Train Loss: 1.220..  Train_Acc: 0.628..  Val Loss: 1.485..  Val_Acc: 0.366\n",
            "Epoch: 715/1000..  Train Loss: 1.222..  Train_Acc: 0.628..  Val Loss: 1.476..  Val_Acc: 0.379\n",
            "Epoch: 716/1000..  Train Loss: 1.221..  Train_Acc: 0.630..  Val Loss: 1.469..  Val_Acc: 0.380\n",
            "Epoch: 717/1000..  Train Loss: 1.221..  Train_Acc: 0.631..  Val Loss: 1.476..  Val_Acc: 0.363\n",
            "Epoch: 718/1000..  Train Loss: 1.226..  Train_Acc: 0.629..  Val Loss: 1.488..  Val_Acc: 0.367\n",
            "Epoch: 719/1000..  Train Loss: 1.226..  Train_Acc: 0.627..  Val Loss: 1.488..  Val_Acc: 0.364\n",
            "Epoch: 720/1000..  Train Loss: 1.220..  Train_Acc: 0.630..  Val Loss: 1.482..  Val_Acc: 0.366\n",
            "Epoch: 721/1000..  Train Loss: 1.217..  Train_Acc: 0.636..  Val Loss: 1.485..  Val_Acc: 0.368\n",
            "Epoch: 722/1000..  Train Loss: 1.216..  Train_Acc: 0.632..  Val Loss: 1.482..  Val_Acc: 0.368\n",
            "Epoch: 723/1000..  Train Loss: 1.219..  Train_Acc: 0.631..  Val Loss: 1.493..  Val_Acc: 0.362\n",
            "Epoch: 724/1000..  Train Loss: 1.220..  Train_Acc: 0.628..  Val Loss: 1.497..  Val_Acc: 0.356\n",
            "Epoch: 725/1000..  Train Loss: 1.218..  Train_Acc: 0.629..  Val Loss: 1.487..  Val_Acc: 0.360\n",
            "Epoch: 726/1000..  Train Loss: 1.223..  Train_Acc: 0.629..  Val Loss: 1.491..  Val_Acc: 0.351\n",
            "Epoch: 727/1000..  Train Loss: 1.212..  Train_Acc: 0.638..  Val Loss: 1.487..  Val_Acc: 0.362\n",
            "Epoch: 728/1000..  Train Loss: 1.219..  Train_Acc: 0.632..  Val Loss: 1.496..  Val_Acc: 0.358\n",
            "Epoch: 729/1000..  Train Loss: 1.211..  Train_Acc: 0.639..  Val Loss: 1.491..  Val_Acc: 0.359\n",
            "Epoch: 730/1000..  Train Loss: 1.210..  Train_Acc: 0.643..  Val Loss: 1.461..  Val_Acc: 0.383\n",
            "Epoch: 731/1000..  Train Loss: 1.218..  Train_Acc: 0.633..  Val Loss: 1.475..  Val_Acc: 0.372\n",
            "Epoch: 732/1000..  Train Loss: 1.215..  Train_Acc: 0.632..  Val Loss: 1.496..  Val_Acc: 0.355\n",
            "Epoch: 733/1000..  Train Loss: 1.214..  Train_Acc: 0.639..  Val Loss: 1.509..  Val_Acc: 0.349\n",
            "Epoch: 734/1000..  Train Loss: 1.221..  Train_Acc: 0.625..  Val Loss: 1.489..  Val_Acc: 0.362\n",
            "Epoch: 735/1000..  Train Loss: 1.214..  Train_Acc: 0.635..  Val Loss: 1.489..  Val_Acc: 0.364\n",
            "Epoch: 736/1000..  Train Loss: 1.216..  Train_Acc: 0.630..  Val Loss: 1.490..  Val_Acc: 0.361\n",
            "Epoch: 737/1000..  Train Loss: 1.224..  Train_Acc: 0.624..  Val Loss: 1.479..  Val_Acc: 0.372\n",
            "Epoch: 738/1000..  Train Loss: 1.211..  Train_Acc: 0.642..  Val Loss: 1.481..  Val_Acc: 0.370\n",
            "Epoch: 739/1000..  Train Loss: 1.226..  Train_Acc: 0.624..  Val Loss: 1.500..  Val_Acc: 0.350\n",
            "Epoch: 740/1000..  Train Loss: 1.218..  Train_Acc: 0.632..  Val Loss: 1.511..  Val_Acc: 0.344\n",
            "Epoch: 741/1000..  Train Loss: 1.214..  Train_Acc: 0.639..  Val Loss: 1.505..  Val_Acc: 0.353\n",
            "Epoch: 742/1000..  Train Loss: 1.221..  Train_Acc: 0.629..  Val Loss: 1.496..  Val_Acc: 0.362\n",
            "Epoch: 743/1000..  Train Loss: 1.219..  Train_Acc: 0.632..  Val Loss: 1.502..  Val_Acc: 0.357\n",
            "Epoch: 744/1000..  Train Loss: 1.221..  Train_Acc: 0.625..  Val Loss: 1.495..  Val_Acc: 0.355\n",
            "Epoch: 745/1000..  Train Loss: 1.216..  Train_Acc: 0.634..  Val Loss: 1.499..  Val_Acc: 0.356\n",
            "Epoch: 746/1000..  Train Loss: 1.215..  Train_Acc: 0.635..  Val Loss: 1.494..  Val_Acc: 0.355\n",
            "Epoch: 747/1000..  Train Loss: 1.216..  Train_Acc: 0.632..  Val Loss: 1.489..  Val_Acc: 0.358\n",
            "Epoch: 748/1000..  Train Loss: 1.218..  Train_Acc: 0.630..  Val Loss: 1.505..  Val_Acc: 0.347\n",
            "Epoch: 749/1000..  Train Loss: 1.215..  Train_Acc: 0.636..  Val Loss: 1.500..  Val_Acc: 0.355\n",
            "Epoch: 750/1000..  Train Loss: 1.212..  Train_Acc: 0.641..  Val Loss: 1.487..  Val_Acc: 0.366\n",
            "Epoch: 751/1000..  Train Loss: 1.207..  Train_Acc: 0.644..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 752/1000..  Train Loss: 1.209..  Train_Acc: 0.644..  Val Loss: 1.493..  Val_Acc: 0.350\n",
            "Epoch: 753/1000..  Train Loss: 1.214..  Train_Acc: 0.639..  Val Loss: 1.490..  Val_Acc: 0.362\n",
            "Epoch: 754/1000..  Train Loss: 1.213..  Train_Acc: 0.637..  Val Loss: 1.488..  Val_Acc: 0.367\n",
            "Epoch: 755/1000..  Train Loss: 1.223..  Train_Acc: 0.628..  Val Loss: 1.495..  Val_Acc: 0.353\n",
            "Epoch: 756/1000..  Train Loss: 1.208..  Train_Acc: 0.644..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 757/1000..  Train Loss: 1.210..  Train_Acc: 0.644..  Val Loss: 1.491..  Val_Acc: 0.361\n",
            "Epoch: 758/1000..  Train Loss: 1.215..  Train_Acc: 0.634..  Val Loss: 1.491..  Val_Acc: 0.360\n",
            "Epoch: 759/1000..  Train Loss: 1.213..  Train_Acc: 0.638..  Val Loss: 1.498..  Val_Acc: 0.349\n",
            "Epoch: 760/1000..  Train Loss: 1.208..  Train_Acc: 0.645..  Val Loss: 1.513..  Val_Acc: 0.341\n",
            "Epoch: 761/1000..  Train Loss: 1.216..  Train_Acc: 0.641..  Val Loss: 1.492..  Val_Acc: 0.355\n",
            "Epoch: 762/1000..  Train Loss: 1.212..  Train_Acc: 0.632..  Val Loss: 1.495..  Val_Acc: 0.355\n",
            "Epoch: 763/1000..  Train Loss: 1.208..  Train_Acc: 0.649..  Val Loss: 1.500..  Val_Acc: 0.349\n",
            "Epoch: 764/1000..  Train Loss: 1.219..  Train_Acc: 0.632..  Val Loss: 1.504..  Val_Acc: 0.355\n",
            "Epoch: 765/1000..  Train Loss: 1.214..  Train_Acc: 0.638..  Val Loss: 1.487..  Val_Acc: 0.358\n",
            "Epoch: 766/1000..  Train Loss: 1.209..  Train_Acc: 0.643..  Val Loss: 1.483..  Val_Acc: 0.362\n",
            "Epoch: 767/1000..  Train Loss: 1.209..  Train_Acc: 0.642..  Val Loss: 1.487..  Val_Acc: 0.359\n",
            "Epoch: 768/1000..  Train Loss: 1.208..  Train_Acc: 0.643..  Val Loss: 1.489..  Val_Acc: 0.360\n",
            "Epoch: 769/1000..  Train Loss: 1.216..  Train_Acc: 0.632..  Val Loss: 1.487..  Val_Acc: 0.361\n",
            "Epoch: 770/1000..  Train Loss: 1.215..  Train_Acc: 0.638..  Val Loss: 1.488..  Val_Acc: 0.362\n",
            "Epoch: 771/1000..  Train Loss: 1.210..  Train_Acc: 0.642..  Val Loss: 1.495..  Val_Acc: 0.354\n",
            "Epoch: 772/1000..  Train Loss: 1.211..  Train_Acc: 0.642..  Val Loss: 1.496..  Val_Acc: 0.360\n",
            "Epoch: 773/1000..  Train Loss: 1.210..  Train_Acc: 0.646..  Val Loss: 1.514..  Val_Acc: 0.341\n",
            "Epoch: 774/1000..  Train Loss: 1.213..  Train_Acc: 0.639..  Val Loss: 1.507..  Val_Acc: 0.346\n",
            "Epoch: 775/1000..  Train Loss: 1.210..  Train_Acc: 0.638..  Val Loss: 1.512..  Val_Acc: 0.348\n",
            "Epoch: 776/1000..  Train Loss: 1.213..  Train_Acc: 0.639..  Val Loss: 1.509..  Val_Acc: 0.344\n",
            "Epoch: 777/1000..  Train Loss: 1.206..  Train_Acc: 0.648..  Val Loss: 1.490..  Val_Acc: 0.362\n",
            "Epoch: 778/1000..  Train Loss: 1.207..  Train_Acc: 0.647..  Val Loss: 1.496..  Val_Acc: 0.353\n",
            "Epoch: 779/1000..  Train Loss: 1.206..  Train_Acc: 0.643..  Val Loss: 1.508..  Val_Acc: 0.344\n",
            "Epoch: 780/1000..  Train Loss: 1.205..  Train_Acc: 0.644..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 781/1000..  Train Loss: 1.210..  Train_Acc: 0.638..  Val Loss: 1.507..  Val_Acc: 0.346\n",
            "Epoch: 782/1000..  Train Loss: 1.217..  Train_Acc: 0.631..  Val Loss: 1.503..  Val_Acc: 0.352\n",
            "Epoch: 783/1000..  Train Loss: 1.208..  Train_Acc: 0.645..  Val Loss: 1.495..  Val_Acc: 0.354\n",
            "Epoch: 784/1000..  Train Loss: 1.206..  Train_Acc: 0.647..  Val Loss: 1.500..  Val_Acc: 0.345\n",
            "Epoch: 785/1000..  Train Loss: 1.214..  Train_Acc: 0.638..  Val Loss: 1.499..  Val_Acc: 0.358\n",
            "Epoch: 786/1000..  Train Loss: 1.205..  Train_Acc: 0.646..  Val Loss: 1.497..  Val_Acc: 0.359\n",
            "Epoch: 787/1000..  Train Loss: 1.208..  Train_Acc: 0.643..  Val Loss: 1.501..  Val_Acc: 0.361\n",
            "Epoch: 788/1000..  Train Loss: 1.209..  Train_Acc: 0.640..  Val Loss: 1.490..  Val_Acc: 0.360\n",
            "Epoch: 789/1000..  Train Loss: 1.205..  Train_Acc: 0.645..  Val Loss: 1.505..  Val_Acc: 0.344\n",
            "Epoch: 790/1000..  Train Loss: 1.209..  Train_Acc: 0.640..  Val Loss: 1.494..  Val_Acc: 0.362\n",
            "Epoch: 791/1000..  Train Loss: 1.210..  Train_Acc: 0.643..  Val Loss: 1.477..  Val_Acc: 0.368\n",
            "Epoch: 792/1000..  Train Loss: 1.212..  Train_Acc: 0.637..  Val Loss: 1.489..  Val_Acc: 0.359\n",
            "Epoch: 793/1000..  Train Loss: 1.203..  Train_Acc: 0.651..  Val Loss: 1.486..  Val_Acc: 0.366\n",
            "Epoch: 794/1000..  Train Loss: 1.212..  Train_Acc: 0.641..  Val Loss: 1.498..  Val_Acc: 0.351\n",
            "Epoch: 795/1000..  Train Loss: 1.205..  Train_Acc: 0.645..  Val Loss: 1.479..  Val_Acc: 0.362\n",
            "Epoch: 796/1000..  Train Loss: 1.212..  Train_Acc: 0.638..  Val Loss: 1.478..  Val_Acc: 0.365\n",
            "Epoch: 797/1000..  Train Loss: 1.198..  Train_Acc: 0.657..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 798/1000..  Train Loss: 1.203..  Train_Acc: 0.645..  Val Loss: 1.489..  Val_Acc: 0.359\n",
            "Epoch: 799/1000..  Train Loss: 1.214..  Train_Acc: 0.635..  Val Loss: 1.490..  Val_Acc: 0.357\n",
            "Epoch: 800/1000..  Train Loss: 1.200..  Train_Acc: 0.654..  Val Loss: 1.494..  Val_Acc: 0.354\n",
            "Epoch: 801/1000..  Train Loss: 1.208..  Train_Acc: 0.640..  Val Loss: 1.515..  Val_Acc: 0.336\n",
            "Epoch: 802/1000..  Train Loss: 1.209..  Train_Acc: 0.648..  Val Loss: 1.515..  Val_Acc: 0.335\n",
            "Epoch: 803/1000..  Train Loss: 1.205..  Train_Acc: 0.645..  Val Loss: 1.513..  Val_Acc: 0.337\n",
            "Epoch: 804/1000..  Train Loss: 1.210..  Train_Acc: 0.637..  Val Loss: 1.501..  Val_Acc: 0.356\n",
            "Epoch: 805/1000..  Train Loss: 1.206..  Train_Acc: 0.645..  Val Loss: 1.518..  Val_Acc: 0.335\n",
            "Epoch: 806/1000..  Train Loss: 1.210..  Train_Acc: 0.640..  Val Loss: 1.508..  Val_Acc: 0.347\n",
            "Epoch: 807/1000..  Train Loss: 1.210..  Train_Acc: 0.643..  Val Loss: 1.494..  Val_Acc: 0.355\n",
            "Epoch: 808/1000..  Train Loss: 1.209..  Train_Acc: 0.640..  Val Loss: 1.505..  Val_Acc: 0.342\n",
            "Epoch: 809/1000..  Train Loss: 1.209..  Train_Acc: 0.644..  Val Loss: 1.501..  Val_Acc: 0.349\n",
            "Epoch: 810/1000..  Train Loss: 1.205..  Train_Acc: 0.649..  Val Loss: 1.495..  Val_Acc: 0.362\n",
            "Epoch: 811/1000..  Train Loss: 1.198..  Train_Acc: 0.654..  Val Loss: 1.503..  Val_Acc: 0.350\n",
            "Epoch: 812/1000..  Train Loss: 1.201..  Train_Acc: 0.644..  Val Loss: 1.485..  Val_Acc: 0.365\n",
            "Epoch: 813/1000..  Train Loss: 1.206..  Train_Acc: 0.643..  Val Loss: 1.486..  Val_Acc: 0.356\n",
            "Epoch: 814/1000..  Train Loss: 1.208..  Train_Acc: 0.647..  Val Loss: 1.489..  Val_Acc: 0.363\n",
            "Epoch: 815/1000..  Train Loss: 1.203..  Train_Acc: 0.648..  Val Loss: 1.481..  Val_Acc: 0.363\n",
            "Epoch: 816/1000..  Train Loss: 1.205..  Train_Acc: 0.644..  Val Loss: 1.481..  Val_Acc: 0.372\n",
            "Epoch: 817/1000..  Train Loss: 1.211..  Train_Acc: 0.636..  Val Loss: 1.497..  Val_Acc: 0.358\n",
            "Epoch: 818/1000..  Train Loss: 1.205..  Train_Acc: 0.644..  Val Loss: 1.484..  Val_Acc: 0.362\n",
            "Epoch: 819/1000..  Train Loss: 1.211..  Train_Acc: 0.638..  Val Loss: 1.492..  Val_Acc: 0.359\n",
            "Epoch: 820/1000..  Train Loss: 1.202..  Train_Acc: 0.646..  Val Loss: 1.483..  Val_Acc: 0.371\n",
            "Epoch: 821/1000..  Train Loss: 1.205..  Train_Acc: 0.641..  Val Loss: 1.492..  Val_Acc: 0.362\n",
            "Epoch: 822/1000..  Train Loss: 1.204..  Train_Acc: 0.650..  Val Loss: 1.490..  Val_Acc: 0.355\n",
            "Epoch: 823/1000..  Train Loss: 1.207..  Train_Acc: 0.640..  Val Loss: 1.503..  Val_Acc: 0.350\n",
            "Epoch: 824/1000..  Train Loss: 1.206..  Train_Acc: 0.646..  Val Loss: 1.486..  Val_Acc: 0.361\n",
            "Epoch: 825/1000..  Train Loss: 1.208..  Train_Acc: 0.641..  Val Loss: 1.496..  Val_Acc: 0.359\n",
            "Epoch: 826/1000..  Train Loss: 1.200..  Train_Acc: 0.645..  Val Loss: 1.498..  Val_Acc: 0.356\n",
            "Epoch: 827/1000..  Train Loss: 1.209..  Train_Acc: 0.645..  Val Loss: 1.495..  Val_Acc: 0.356\n",
            "Epoch: 828/1000..  Train Loss: 1.201..  Train_Acc: 0.651..  Val Loss: 1.495..  Val_Acc: 0.355\n",
            "Epoch: 829/1000..  Train Loss: 1.201..  Train_Acc: 0.649..  Val Loss: 1.486..  Val_Acc: 0.363\n",
            "Epoch: 830/1000..  Train Loss: 1.205..  Train_Acc: 0.645..  Val Loss: 1.506..  Val_Acc: 0.355\n",
            "Epoch: 831/1000..  Train Loss: 1.206..  Train_Acc: 0.645..  Val Loss: 1.516..  Val_Acc: 0.342\n",
            "Epoch: 832/1000..  Train Loss: 1.204..  Train_Acc: 0.648..  Val Loss: 1.493..  Val_Acc: 0.354\n",
            "Epoch: 833/1000..  Train Loss: 1.202..  Train_Acc: 0.646..  Val Loss: 1.502..  Val_Acc: 0.349\n",
            "Epoch: 834/1000..  Train Loss: 1.205..  Train_Acc: 0.645..  Val Loss: 1.488..  Val_Acc: 0.366\n",
            "Epoch: 835/1000..  Train Loss: 1.204..  Train_Acc: 0.647..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 836/1000..  Train Loss: 1.202..  Train_Acc: 0.651..  Val Loss: 1.497..  Val_Acc: 0.356\n",
            "Epoch: 837/1000..  Train Loss: 1.202..  Train_Acc: 0.649..  Val Loss: 1.502..  Val_Acc: 0.356\n",
            "Epoch: 838/1000..  Train Loss: 1.208..  Train_Acc: 0.642..  Val Loss: 1.506..  Val_Acc: 0.344\n",
            "Epoch: 839/1000..  Train Loss: 1.199..  Train_Acc: 0.652..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 840/1000..  Train Loss: 1.201..  Train_Acc: 0.651..  Val Loss: 1.477..  Val_Acc: 0.367\n",
            "Epoch: 841/1000..  Train Loss: 1.207..  Train_Acc: 0.642..  Val Loss: 1.500..  Val_Acc: 0.352\n",
            "Epoch: 842/1000..  Train Loss: 1.198..  Train_Acc: 0.647..  Val Loss: 1.488..  Val_Acc: 0.356\n",
            "Epoch: 843/1000..  Train Loss: 1.199..  Train_Acc: 0.656..  Val Loss: 1.493..  Val_Acc: 0.354\n",
            "Epoch: 844/1000..  Train Loss: 1.203..  Train_Acc: 0.647..  Val Loss: 1.498..  Val_Acc: 0.351\n",
            "Epoch: 845/1000..  Train Loss: 1.200..  Train_Acc: 0.651..  Val Loss: 1.503..  Val_Acc: 0.346\n",
            "Epoch: 846/1000..  Train Loss: 1.210..  Train_Acc: 0.642..  Val Loss: 1.501..  Val_Acc: 0.354\n",
            "Epoch: 847/1000..  Train Loss: 1.196..  Train_Acc: 0.651..  Val Loss: 1.498..  Val_Acc: 0.359\n",
            "Epoch: 848/1000..  Train Loss: 1.197..  Train_Acc: 0.656..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 849/1000..  Train Loss: 1.197..  Train_Acc: 0.655..  Val Loss: 1.483..  Val_Acc: 0.364\n",
            "Epoch: 850/1000..  Train Loss: 1.200..  Train_Acc: 0.649..  Val Loss: 1.487..  Val_Acc: 0.356\n",
            "Epoch: 851/1000..  Train Loss: 1.207..  Train_Acc: 0.645..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 852/1000..  Train Loss: 1.196..  Train_Acc: 0.653..  Val Loss: 1.480..  Val_Acc: 0.366\n",
            "Epoch: 853/1000..  Train Loss: 1.196..  Train_Acc: 0.651..  Val Loss: 1.490..  Val_Acc: 0.359\n",
            "Epoch: 854/1000..  Train Loss: 1.200..  Train_Acc: 0.649..  Val Loss: 1.486..  Val_Acc: 0.366\n",
            "Epoch: 855/1000..  Train Loss: 1.205..  Train_Acc: 0.646..  Val Loss: 1.492..  Val_Acc: 0.364\n",
            "Epoch: 856/1000..  Train Loss: 1.193..  Train_Acc: 0.655..  Val Loss: 1.485..  Val_Acc: 0.370\n",
            "Epoch: 857/1000..  Train Loss: 1.205..  Train_Acc: 0.643..  Val Loss: 1.491..  Val_Acc: 0.358\n",
            "Epoch: 858/1000..  Train Loss: 1.193..  Train_Acc: 0.655..  Val Loss: 1.489..  Val_Acc: 0.359\n",
            "Epoch: 859/1000..  Train Loss: 1.202..  Train_Acc: 0.650..  Val Loss: 1.488..  Val_Acc: 0.360\n",
            "Epoch: 860/1000..  Train Loss: 1.203..  Train_Acc: 0.651..  Val Loss: 1.500..  Val_Acc: 0.352\n",
            "Epoch: 861/1000..  Train Loss: 1.204..  Train_Acc: 0.646..  Val Loss: 1.501..  Val_Acc: 0.351\n",
            "Epoch: 862/1000..  Train Loss: 1.198..  Train_Acc: 0.651..  Val Loss: 1.488..  Val_Acc: 0.369\n",
            "Epoch: 863/1000..  Train Loss: 1.198..  Train_Acc: 0.646..  Val Loss: 1.501..  Val_Acc: 0.350\n",
            "Epoch: 864/1000..  Train Loss: 1.200..  Train_Acc: 0.653..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 865/1000..  Train Loss: 1.206..  Train_Acc: 0.645..  Val Loss: 1.487..  Val_Acc: 0.366\n",
            "Epoch: 866/1000..  Train Loss: 1.201..  Train_Acc: 0.648..  Val Loss: 1.507..  Val_Acc: 0.347\n",
            "Epoch: 867/1000..  Train Loss: 1.201..  Train_Acc: 0.655..  Val Loss: 1.505..  Val_Acc: 0.347\n",
            "Epoch: 868/1000..  Train Loss: 1.199..  Train_Acc: 0.653..  Val Loss: 1.499..  Val_Acc: 0.360\n",
            "Epoch: 869/1000..  Train Loss: 1.199..  Train_Acc: 0.648..  Val Loss: 1.501..  Val_Acc: 0.353\n",
            "Epoch: 870/1000..  Train Loss: 1.206..  Train_Acc: 0.641..  Val Loss: 1.481..  Val_Acc: 0.373\n",
            "Epoch: 871/1000..  Train Loss: 1.201..  Train_Acc: 0.650..  Val Loss: 1.493..  Val_Acc: 0.359\n",
            "Epoch: 872/1000..  Train Loss: 1.201..  Train_Acc: 0.646..  Val Loss: 1.480..  Val_Acc: 0.371\n",
            "Epoch: 873/1000..  Train Loss: 1.195..  Train_Acc: 0.657..  Val Loss: 1.485..  Val_Acc: 0.359\n",
            "Epoch: 874/1000..  Train Loss: 1.199..  Train_Acc: 0.652..  Val Loss: 1.488..  Val_Acc: 0.358\n",
            "Epoch: 875/1000..  Train Loss: 1.215..  Train_Acc: 0.631..  Val Loss: 1.512..  Val_Acc: 0.347\n",
            "Epoch: 876/1000..  Train Loss: 1.200..  Train_Acc: 0.653..  Val Loss: 1.480..  Val_Acc: 0.369\n",
            "Epoch: 877/1000..  Train Loss: 1.199..  Train_Acc: 0.641..  Val Loss: 1.494..  Val_Acc: 0.362\n",
            "Epoch: 878/1000..  Train Loss: 1.196..  Train_Acc: 0.652..  Val Loss: 1.496..  Val_Acc: 0.353\n",
            "Epoch: 879/1000..  Train Loss: 1.200..  Train_Acc: 0.650..  Val Loss: 1.494..  Val_Acc: 0.358\n",
            "Epoch: 880/1000..  Train Loss: 1.202..  Train_Acc: 0.649..  Val Loss: 1.482..  Val_Acc: 0.371\n",
            "Epoch: 881/1000..  Train Loss: 1.194..  Train_Acc: 0.654..  Val Loss: 1.494..  Val_Acc: 0.360\n",
            "Epoch: 882/1000..  Train Loss: 1.191..  Train_Acc: 0.659..  Val Loss: 1.491..  Val_Acc: 0.368\n",
            "Epoch: 883/1000..  Train Loss: 1.201..  Train_Acc: 0.647..  Val Loss: 1.496..  Val_Acc: 0.350\n",
            "Epoch: 884/1000..  Train Loss: 1.203..  Train_Acc: 0.645..  Val Loss: 1.517..  Val_Acc: 0.338\n",
            "Epoch: 885/1000..  Train Loss: 1.212..  Train_Acc: 0.638..  Val Loss: 1.495..  Val_Acc: 0.356\n",
            "Epoch: 886/1000..  Train Loss: 1.202..  Train_Acc: 0.647..  Val Loss: 1.486..  Val_Acc: 0.359\n",
            "Epoch: 887/1000..  Train Loss: 1.194..  Train_Acc: 0.659..  Val Loss: 1.492..  Val_Acc: 0.359\n",
            "Epoch: 888/1000..  Train Loss: 1.197..  Train_Acc: 0.654..  Val Loss: 1.491..  Val_Acc: 0.360\n",
            "Epoch: 889/1000..  Train Loss: 1.196..  Train_Acc: 0.657..  Val Loss: 1.484..  Val_Acc: 0.370\n",
            "Epoch: 890/1000..  Train Loss: 1.201..  Train_Acc: 0.648..  Val Loss: 1.488..  Val_Acc: 0.363\n",
            "Epoch: 891/1000..  Train Loss: 1.190..  Train_Acc: 0.660..  Val Loss: 1.501..  Val_Acc: 0.351\n",
            "Epoch: 892/1000..  Train Loss: 1.195..  Train_Acc: 0.657..  Val Loss: 1.489..  Val_Acc: 0.361\n",
            "Epoch: 893/1000..  Train Loss: 1.197..  Train_Acc: 0.657..  Val Loss: 1.481..  Val_Acc: 0.366\n",
            "Epoch: 894/1000..  Train Loss: 1.202..  Train_Acc: 0.651..  Val Loss: 1.479..  Val_Acc: 0.367\n",
            "Epoch: 895/1000..  Train Loss: 1.193..  Train_Acc: 0.661..  Val Loss: 1.493..  Val_Acc: 0.361\n",
            "Epoch: 896/1000..  Train Loss: 1.200..  Train_Acc: 0.652..  Val Loss: 1.486..  Val_Acc: 0.363\n",
            "Epoch: 897/1000..  Train Loss: 1.194..  Train_Acc: 0.660..  Val Loss: 1.504..  Val_Acc: 0.352\n",
            "Epoch: 898/1000..  Train Loss: 1.198..  Train_Acc: 0.655..  Val Loss: 1.497..  Val_Acc: 0.363\n",
            "Epoch: 899/1000..  Train Loss: 1.198..  Train_Acc: 0.655..  Val Loss: 1.482..  Val_Acc: 0.365\n",
            "Epoch: 900/1000..  Train Loss: 1.202..  Train_Acc: 0.646..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 901/1000..  Train Loss: 1.198..  Train_Acc: 0.648..  Val Loss: 1.501..  Val_Acc: 0.359\n",
            "Epoch: 902/1000..  Train Loss: 1.202..  Train_Acc: 0.650..  Val Loss: 1.500..  Val_Acc: 0.360\n",
            "Epoch: 903/1000..  Train Loss: 1.196..  Train_Acc: 0.654..  Val Loss: 1.491..  Val_Acc: 0.363\n",
            "Epoch: 904/1000..  Train Loss: 1.197..  Train_Acc: 0.652..  Val Loss: 1.491..  Val_Acc: 0.366\n",
            "Epoch: 905/1000..  Train Loss: 1.190..  Train_Acc: 0.662..  Val Loss: 1.492..  Val_Acc: 0.359\n",
            "Epoch: 906/1000..  Train Loss: 1.198..  Train_Acc: 0.657..  Val Loss: 1.477..  Val_Acc: 0.371\n",
            "Epoch: 907/1000..  Train Loss: 1.201..  Train_Acc: 0.651..  Val Loss: 1.498..  Val_Acc: 0.349\n",
            "Epoch: 908/1000..  Train Loss: 1.196..  Train_Acc: 0.654..  Val Loss: 1.484..  Val_Acc: 0.368\n",
            "Epoch: 909/1000..  Train Loss: 1.189..  Train_Acc: 0.665..  Val Loss: 1.489..  Val_Acc: 0.359\n",
            "Epoch: 910/1000..  Train Loss: 1.197..  Train_Acc: 0.651..  Val Loss: 1.501..  Val_Acc: 0.353\n",
            "Epoch: 911/1000..  Train Loss: 1.188..  Train_Acc: 0.664..  Val Loss: 1.498..  Val_Acc: 0.353\n",
            "Epoch: 912/1000..  Train Loss: 1.194..  Train_Acc: 0.658..  Val Loss: 1.494..  Val_Acc: 0.360\n",
            "Epoch: 913/1000..  Train Loss: 1.190..  Train_Acc: 0.658..  Val Loss: 1.499..  Val_Acc: 0.350\n",
            "Epoch: 914/1000..  Train Loss: 1.194..  Train_Acc: 0.658..  Val Loss: 1.500..  Val_Acc: 0.349\n",
            "Epoch: 915/1000..  Train Loss: 1.200..  Train_Acc: 0.648..  Val Loss: 1.500..  Val_Acc: 0.352\n",
            "Epoch: 916/1000..  Train Loss: 1.197..  Train_Acc: 0.656..  Val Loss: 1.491..  Val_Acc: 0.362\n",
            "Epoch: 917/1000..  Train Loss: 1.189..  Train_Acc: 0.660..  Val Loss: 1.476..  Val_Acc: 0.370\n",
            "Epoch: 918/1000..  Train Loss: 1.192..  Train_Acc: 0.659..  Val Loss: 1.495..  Val_Acc: 0.359\n",
            "Epoch: 919/1000..  Train Loss: 1.198..  Train_Acc: 0.649..  Val Loss: 1.489..  Val_Acc: 0.357\n",
            "Epoch: 920/1000..  Train Loss: 1.194..  Train_Acc: 0.657..  Val Loss: 1.487..  Val_Acc: 0.359\n",
            "Epoch: 921/1000..  Train Loss: 1.197..  Train_Acc: 0.652..  Val Loss: 1.491..  Val_Acc: 0.358\n",
            "Epoch: 922/1000..  Train Loss: 1.193..  Train_Acc: 0.657..  Val Loss: 1.476..  Val_Acc: 0.370\n",
            "Epoch: 923/1000..  Train Loss: 1.195..  Train_Acc: 0.657..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 924/1000..  Train Loss: 1.193..  Train_Acc: 0.659..  Val Loss: 1.494..  Val_Acc: 0.359\n",
            "Epoch: 925/1000..  Train Loss: 1.196..  Train_Acc: 0.658..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 926/1000..  Train Loss: 1.197..  Train_Acc: 0.655..  Val Loss: 1.489..  Val_Acc: 0.366\n",
            "Epoch: 927/1000..  Train Loss: 1.191..  Train_Acc: 0.659..  Val Loss: 1.493..  Val_Acc: 0.359\n",
            "Epoch: 928/1000..  Train Loss: 1.190..  Train_Acc: 0.660..  Val Loss: 1.498..  Val_Acc: 0.355\n",
            "Epoch: 929/1000..  Train Loss: 1.184..  Train_Acc: 0.667..  Val Loss: 1.493..  Val_Acc: 0.357\n",
            "Epoch: 930/1000..  Train Loss: 1.188..  Train_Acc: 0.662..  Val Loss: 1.484..  Val_Acc: 0.362\n",
            "Epoch: 931/1000..  Train Loss: 1.196..  Train_Acc: 0.654..  Val Loss: 1.487..  Val_Acc: 0.365\n",
            "Epoch: 932/1000..  Train Loss: 1.194..  Train_Acc: 0.656..  Val Loss: 1.486..  Val_Acc: 0.360\n",
            "Epoch: 933/1000..  Train Loss: 1.185..  Train_Acc: 0.669..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 934/1000..  Train Loss: 1.190..  Train_Acc: 0.662..  Val Loss: 1.488..  Val_Acc: 0.365\n",
            "Epoch: 935/1000..  Train Loss: 1.189..  Train_Acc: 0.659..  Val Loss: 1.492..  Val_Acc: 0.352\n",
            "Epoch: 936/1000..  Train Loss: 1.196..  Train_Acc: 0.646..  Val Loss: 1.488..  Val_Acc: 0.358\n",
            "Epoch: 937/1000..  Train Loss: 1.189..  Train_Acc: 0.660..  Val Loss: 1.476..  Val_Acc: 0.366\n",
            "Epoch: 938/1000..  Train Loss: 1.192..  Train_Acc: 0.658..  Val Loss: 1.482..  Val_Acc: 0.367\n",
            "Epoch: 939/1000..  Train Loss: 1.187..  Train_Acc: 0.666..  Val Loss: 1.482..  Val_Acc: 0.361\n",
            "Epoch: 940/1000..  Train Loss: 1.195..  Train_Acc: 0.652..  Val Loss: 1.485..  Val_Acc: 0.362\n",
            "Epoch: 941/1000..  Train Loss: 1.186..  Train_Acc: 0.665..  Val Loss: 1.494..  Val_Acc: 0.359\n",
            "Epoch: 942/1000..  Train Loss: 1.188..  Train_Acc: 0.662..  Val Loss: 1.479..  Val_Acc: 0.367\n",
            "Epoch: 943/1000..  Train Loss: 1.191..  Train_Acc: 0.660..  Val Loss: 1.482..  Val_Acc: 0.364\n",
            "Epoch: 944/1000..  Train Loss: 1.188..  Train_Acc: 0.666..  Val Loss: 1.497..  Val_Acc: 0.353\n",
            "Epoch: 945/1000..  Train Loss: 1.190..  Train_Acc: 0.660..  Val Loss: 1.473..  Val_Acc: 0.372\n",
            "Epoch: 946/1000..  Train Loss: 1.185..  Train_Acc: 0.664..  Val Loss: 1.484..  Val_Acc: 0.366\n",
            "Epoch: 947/1000..  Train Loss: 1.185..  Train_Acc: 0.666..  Val Loss: 1.483..  Val_Acc: 0.367\n",
            "Epoch: 948/1000..  Train Loss: 1.188..  Train_Acc: 0.662..  Val Loss: 1.491..  Val_Acc: 0.359\n",
            "Epoch: 949/1000..  Train Loss: 1.186..  Train_Acc: 0.665..  Val Loss: 1.489..  Val_Acc: 0.355\n",
            "Epoch: 950/1000..  Train Loss: 1.187..  Train_Acc: 0.663..  Val Loss: 1.480..  Val_Acc: 0.366\n",
            "Epoch: 951/1000..  Train Loss: 1.185..  Train_Acc: 0.663..  Val Loss: 1.484..  Val_Acc: 0.366\n",
            "Epoch: 952/1000..  Train Loss: 1.191..  Train_Acc: 0.659..  Val Loss: 1.488..  Val_Acc: 0.364\n",
            "Epoch: 953/1000..  Train Loss: 1.188..  Train_Acc: 0.666..  Val Loss: 1.487..  Val_Acc: 0.366\n",
            "Epoch: 954/1000..  Train Loss: 1.189..  Train_Acc: 0.661..  Val Loss: 1.484..  Val_Acc: 0.368\n",
            "Epoch: 955/1000..  Train Loss: 1.186..  Train_Acc: 0.667..  Val Loss: 1.496..  Val_Acc: 0.361\n",
            "Epoch: 956/1000..  Train Loss: 1.189..  Train_Acc: 0.661..  Val Loss: 1.509..  Val_Acc: 0.348\n",
            "Epoch: 957/1000..  Train Loss: 1.193..  Train_Acc: 0.655..  Val Loss: 1.497..  Val_Acc: 0.352\n",
            "Epoch: 958/1000..  Train Loss: 1.184..  Train_Acc: 0.671..  Val Loss: 1.504..  Val_Acc: 0.348\n",
            "Epoch: 959/1000..  Train Loss: 1.191..  Train_Acc: 0.658..  Val Loss: 1.484..  Val_Acc: 0.367\n",
            "Epoch: 960/1000..  Train Loss: 1.187..  Train_Acc: 0.669..  Val Loss: 1.503..  Val_Acc: 0.344\n",
            "Epoch: 961/1000..  Train Loss: 1.191..  Train_Acc: 0.662..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 962/1000..  Train Loss: 1.186..  Train_Acc: 0.661..  Val Loss: 1.485..  Val_Acc: 0.372\n",
            "Epoch: 963/1000..  Train Loss: 1.190..  Train_Acc: 0.662..  Val Loss: 1.498..  Val_Acc: 0.356\n",
            "Epoch: 964/1000..  Train Loss: 1.196..  Train_Acc: 0.646..  Val Loss: 1.488..  Val_Acc: 0.359\n",
            "Epoch: 965/1000..  Train Loss: 1.195..  Train_Acc: 0.656..  Val Loss: 1.483..  Val_Acc: 0.370\n",
            "Epoch: 966/1000..  Train Loss: 1.190..  Train_Acc: 0.657..  Val Loss: 1.489..  Val_Acc: 0.361\n",
            "Epoch: 967/1000..  Train Loss: 1.193..  Train_Acc: 0.658..  Val Loss: 1.497..  Val_Acc: 0.358\n",
            "Epoch: 968/1000..  Train Loss: 1.190..  Train_Acc: 0.658..  Val Loss: 1.486..  Val_Acc: 0.360\n",
            "Epoch: 969/1000..  Train Loss: 1.184..  Train_Acc: 0.669..  Val Loss: 1.482..  Val_Acc: 0.366\n",
            "Epoch: 970/1000..  Train Loss: 1.192..  Train_Acc: 0.658..  Val Loss: 1.483..  Val_Acc: 0.365\n",
            "Epoch: 971/1000..  Train Loss: 1.190..  Train_Acc: 0.659..  Val Loss: 1.480..  Val_Acc: 0.361\n",
            "Epoch: 972/1000..  Train Loss: 1.187..  Train_Acc: 0.664..  Val Loss: 1.485..  Val_Acc: 0.357\n",
            "Epoch: 973/1000..  Train Loss: 1.186..  Train_Acc: 0.667..  Val Loss: 1.479..  Val_Acc: 0.366\n",
            "Epoch: 974/1000..  Train Loss: 1.193..  Train_Acc: 0.654..  Val Loss: 1.475..  Val_Acc: 0.370\n",
            "Epoch: 975/1000..  Train Loss: 1.188..  Train_Acc: 0.664..  Val Loss: 1.478..  Val_Acc: 0.373\n",
            "Epoch: 976/1000..  Train Loss: 1.191..  Train_Acc: 0.667..  Val Loss: 1.484..  Val_Acc: 0.361\n",
            "Epoch: 977/1000..  Train Loss: 1.185..  Train_Acc: 0.659..  Val Loss: 1.487..  Val_Acc: 0.360\n",
            "Epoch: 978/1000..  Train Loss: 1.184..  Train_Acc: 0.666..  Val Loss: 1.489..  Val_Acc: 0.365\n",
            "Epoch: 979/1000..  Train Loss: 1.181..  Train_Acc: 0.671..  Val Loss: 1.490..  Val_Acc: 0.359\n",
            "Epoch: 980/1000..  Train Loss: 1.184..  Train_Acc: 0.668..  Val Loss: 1.483..  Val_Acc: 0.362\n",
            "Epoch: 981/1000..  Train Loss: 1.185..  Train_Acc: 0.662..  Val Loss: 1.491..  Val_Acc: 0.362\n",
            "Epoch: 982/1000..  Train Loss: 1.189..  Train_Acc: 0.662..  Val Loss: 1.498..  Val_Acc: 0.352\n",
            "Epoch: 983/1000..  Train Loss: 1.188..  Train_Acc: 0.660..  Val Loss: 1.502..  Val_Acc: 0.350\n",
            "Epoch: 984/1000..  Train Loss: 1.190..  Train_Acc: 0.664..  Val Loss: 1.492..  Val_Acc: 0.360\n",
            "Epoch: 985/1000..  Train Loss: 1.188..  Train_Acc: 0.660..  Val Loss: 1.496..  Val_Acc: 0.361\n",
            "Epoch: 986/1000..  Train Loss: 1.187..  Train_Acc: 0.664..  Val Loss: 1.491..  Val_Acc: 0.361\n",
            "Epoch: 987/1000..  Train Loss: 1.188..  Train_Acc: 0.668..  Val Loss: 1.488..  Val_Acc: 0.362\n",
            "Epoch: 988/1000..  Train Loss: 1.196..  Train_Acc: 0.658..  Val Loss: 1.493..  Val_Acc: 0.355\n",
            "Epoch: 989/1000..  Train Loss: 1.181..  Train_Acc: 0.674..  Val Loss: 1.494..  Val_Acc: 0.357\n",
            "Epoch: 990/1000..  Train Loss: 1.188..  Train_Acc: 0.661..  Val Loss: 1.487..  Val_Acc: 0.358\n",
            "Epoch: 991/1000..  Train Loss: 1.180..  Train_Acc: 0.672..  Val Loss: 1.500..  Val_Acc: 0.350\n",
            "Epoch: 992/1000..  Train Loss: 1.187..  Train_Acc: 0.664..  Val Loss: 1.493..  Val_Acc: 0.355\n",
            "Epoch: 993/1000..  Train Loss: 1.187..  Train_Acc: 0.662..  Val Loss: 1.502..  Val_Acc: 0.355\n",
            "Epoch: 994/1000..  Train Loss: 1.176..  Train_Acc: 0.677..  Val Loss: 1.499..  Val_Acc: 0.352\n",
            "Epoch: 995/1000..  Train Loss: 1.188..  Train_Acc: 0.661..  Val Loss: 1.494..  Val_Acc: 0.356\n",
            "Epoch: 996/1000..  Train Loss: 1.187..  Train_Acc: 0.663..  Val Loss: 1.488..  Val_Acc: 0.358\n",
            "Epoch: 997/1000..  Train Loss: 1.184..  Train_Acc: 0.666..  Val Loss: 1.495..  Val_Acc: 0.354\n",
            "Epoch: 998/1000..  Train Loss: 1.185..  Train_Acc: 0.665..  Val Loss: 1.506..  Val_Acc: 0.347\n",
            "Epoch: 999/1000..  Train Loss: 1.191..  Train_Acc: 0.666..  Val Loss: 1.491..  Val_Acc: 0.356\n",
            "Epoch: 1000/1000..  Train Loss: 1.187..  Train_Acc: 0.665..  Val Loss: 1.504..  Val_Acc: 0.353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8h_gidnacUD",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsSr6-loaesR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0598d2dc-6c82-4d03-897c-d4bd993a8b4f"
      },
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "for batch in test_iter:\n",
        "    text= batch.text.to(device)\n",
        "    label = batch.label -1\n",
        "    label = label.to(device)\n",
        "\n",
        "    output = model.forward(text)\n",
        "    test_loss += criterion(output,label).item()\n",
        "\n",
        "    test_accuracy += torch.sum(torch.argmax(output,1)==label).cpu().item()/256\n",
        "\n",
        "print(\"Test Loss: {:.3f}.. \".format(test_loss/len(test_iter)),\n",
        "        \"Test Accuracy: {:.3f}\".format(test_accuracy/len(test_iter)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.495..  Test Accuracy: 0.387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuGldlSObLEP",
        "colab_type": "text"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AyywHmnbOPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6acd19b8-4963-4bcf-8b2d-ba1bb5744168"
      },
      "source": [
        "plt.plot(training_loss, label ='Training Loss')\n",
        "plt.plot(validation_loss, label = 'Validation Loss')\n",
        "plt.plot(validation_acc, label = 'Validation Accuracy')\n",
        "plt.legend(frameon = True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa870745518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}